{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3b88ee4-110a-4f3a-b9a1-56138c334518",
   "metadata": {},
   "source": [
    "<h1>Ejercicio 3 Práctica 6 (Iris)</h1>\n",
    "<p>En esta versión de este ejercicio se usa el siguiente dataset: <a>https://www.kaggle.com/datasets/jeffheaton/iris-computer-vision</a>. Es importante destacar que este dataset está desbalanceado, ya que contiene muchas imágenes de la flor versicolor, y pocas de las demás flores (setosa, virginica). Se decidió continuar con este ejercicio para mostrar los efectos de un dataset desbalanceado en el entrenamiento de un modelo CNN y se creó otra versión usando un dataset distinto y más completo (CIFAR10).</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22116e70",
   "metadata": {},
   "source": [
    "<h3>Importaciones</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de43358d-c4bf-4a40-aa34-2ca53ea5459d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Rescaling, RandomFlip, RandomRotation, RandomZoom, GlobalAveragePooling2D, RandomContrast\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a57200",
   "metadata": {},
   "source": [
    "<h3>Carga de datos y división en conjuntos de entrenamiento y validación</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef87c132-6869-4d85-b73e-50ce7d68f40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 423 files belonging to 3 classes.\n",
      "Using 339 files for training.\n",
      "Found 423 files belonging to 3 classes.\n",
      "Using 84 files for validation.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# dataset Iris\n",
    "IMG_SIZE = (256, 256)\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"./iris\",\n",
    "    validation_split=0.2,  # 20% para validación\n",
    "    subset=\"training\",    \n",
    "    seed=123,             \n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "valid_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"./iris\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",  \n",
    "    seed=123,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5693086-2679-446a-bdf3-c27c29637144",
   "metadata": {},
   "source": [
    "<h3>Modificaciones de pesos de clases</h3>\n",
    "<p>Para intentar reducir los efectos del desbalance en los datos, se usa compute_class_weight, que calcula y devuelve pesos teniendo en cuenta el número de ejemplos por clase. Estos pesos penalizan a la clase dominante en los datos y ayudan a aquellas que no tienen muchos ejemplos. Se pasan al modelo antes de comenzar el entrenamiento.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "032429af-a7c9-4b31-b443-e331513cdeff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pesos por clase: {0: 2.1320754716981134, 1: 0.5159817351598174, 2: 1.6865671641791045}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Como se tienen muchos mas ejemplos de la flor iris versicolor, modifico los pesos para intentar balancearlos y buscar permitir el correcto aprendizaje de todas las clases.\n",
    "class_names = train_ds.class_names\n",
    "labels = np.concatenate([y for x, y in train_ds], axis=0)\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.unique(labels),\n",
    "    y=labels\n",
    ")\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "print(\"Pesos por clase:\", class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03e1df3-ffd8-4dd9-ab8d-2ffd0937b333",
   "metadata": {},
   "source": [
    "<h3>Construcción del modelo y entrenamiento</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2282ee65-ec2c-4130-83ae-670d8391c701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\franc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\layers\\preprocessing\\data_layer.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 143ms/step - accuracy: 0.2743 - loss: 1.1047 - val_accuracy: 0.6190 - val_loss: 1.0885\n",
      "Epoch 2/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 123ms/step - accuracy: 0.4159 - loss: 1.0957 - val_accuracy: 0.6071 - val_loss: 1.0898\n",
      "Epoch 3/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 122ms/step - accuracy: 0.3864 - loss: 1.0958 - val_accuracy: 0.4286 - val_loss: 1.0942\n",
      "Epoch 4/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 124ms/step - accuracy: 0.3304 - loss: 1.1067 - val_accuracy: 0.3452 - val_loss: 1.1007\n",
      "Epoch 5/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 124ms/step - accuracy: 0.2861 - loss: 1.0976 - val_accuracy: 0.2976 - val_loss: 1.1000\n",
      "Epoch 6/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 126ms/step - accuracy: 0.3304 - loss: 1.0951 - val_accuracy: 0.5119 - val_loss: 1.0869\n",
      "Epoch 7/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 124ms/step - accuracy: 0.3333 - loss: 1.0938 - val_accuracy: 0.3214 - val_loss: 1.0996\n",
      "Epoch 8/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 123ms/step - accuracy: 0.3569 - loss: 1.0933 - val_accuracy: 0.5119 - val_loss: 1.0732\n",
      "Epoch 9/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 123ms/step - accuracy: 0.2950 - loss: 1.0849 - val_accuracy: 0.3690 - val_loss: 1.0804\n",
      "Epoch 10/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 123ms/step - accuracy: 0.3864 - loss: 1.0779 - val_accuracy: 0.4048 - val_loss: 1.0844\n",
      "Epoch 11/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 125ms/step - accuracy: 0.3392 - loss: 1.0753 - val_accuracy: 0.4762 - val_loss: 1.0689\n",
      "Epoch 12/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 123ms/step - accuracy: 0.4395 - loss: 1.0520 - val_accuracy: 0.3095 - val_loss: 1.1366\n",
      "Epoch 13/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 134ms/step - accuracy: 0.4248 - loss: 1.0408 - val_accuracy: 0.3333 - val_loss: 1.1095\n",
      "Epoch 14/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 124ms/step - accuracy: 0.4012 - loss: 1.0241 - val_accuracy: 0.3333 - val_loss: 1.1323\n",
      "Epoch 15/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 126ms/step - accuracy: 0.3953 - loss: 1.0107 - val_accuracy: 0.2738 - val_loss: 1.2321\n",
      "Epoch 16/30\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 126ms/step - accuracy: 0.4307 - loss: 0.9994 - val_accuracy: 0.3214 - val_loss: 1.1248\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.4762 - loss: 1.0689\n",
      "Accuracy: 0.48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ sequential (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ rescaling (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">254</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">254</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ sequential (\u001b[38;5;33mSequential\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ rescaling (\u001b[38;5;33mRescaling\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m254\u001b[0m, \u001b[38;5;34m254\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m896\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │          \u001b[38;5;34m73,856\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m16,512\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │             \u001b[38;5;34m387\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">330,443</span> (1.26 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m330,443\u001b[0m (1.26 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">110,147</span> (430.26 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m110,147\u001b[0m (430.26 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">220,296</span> (860.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m220,296\u001b[0m (860.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Early stopping para evitar el sobreentrenamiento\n",
    "callback = EarlyStopping(\n",
    "    patience=5, restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Capas para data augmentation, al tener pocos datos\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    RandomFlip(\"horizontal\"),\n",
    "    RandomRotation(0.1),\n",
    "    RandomZoom(0.1),\n",
    "    RandomContrast(0.1),\n",
    "])\n",
    "\n",
    "model = Sequential([\n",
    "    data_augmentation,\n",
    "    Rescaling(1./255, input_shape=(256, 256, 3)),\n",
    "    Conv2D(32, (3,3), activation='relu'),\n",
    "    MaxPooling2D(4,4),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(128, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    GlobalAveragePooling2D(),    \n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_ds, epochs=30, batch_size=BATCH_SIZE, verbose=1, validation_data=valid_ds, class_weight=class_weights, callbacks=callback)\n",
    "loss, acc = model.evaluate(valid_ds)\n",
    "print(f\"Accuracy: {acc:.2f}\")\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b4f9d98-a3eb-4a0c-be8d-f484a58d3d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.25      0.16        16\n",
      "           1       0.61      0.50      0.55        50\n",
      "           2       0.12      0.06      0.08        18\n",
      "\n",
      "    accuracy                           0.36        84\n",
      "   macro avg       0.28      0.27      0.26        84\n",
      "weighted avg       0.41      0.36      0.37        84\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predicciones y estadísticas\n",
    "y_pred = model.predict(valid_ds)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.concatenate([y for x, y in valid_ds], axis=0)\n",
    "print(classification_report(y_true, y_pred_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29fd045-796d-45e8-aa72-2a951f54ba7e",
   "metadata": {},
   "source": [
    "<p>Estas estadísticas finales muestran que el modelo está sesgado y predice en su mayoría la clase 1 (versicolor) para entradas que no lo son. Las otras dos clases (setosa, virginica) son casi ignoradas por el modelo.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7a1a2a-cc88-45b5-b3a3-126197c50bdb",
   "metadata": {},
   "source": [
    "<h1>Ejercicio 3 Práctica 6 (CIFAR10)</h1>\n",
    "<p>En esta versión de este ejercicio se usa el siguiente dataset: <a>https://www.cs.toronto.edu/~kriz/cifar.html</a>.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8fe6c0-cb9c-46da-ad22-dda140cd5a69",
   "metadata": {},
   "source": [
    "<h3>Importaciones y carga de datos</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "effeaace-9b81-4657-8f7e-6467c8b8468a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.datasets import cifar10\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# dataset CIFAR10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2da79c3-a26e-4c64-953e-f0c273f3bfe3",
   "metadata": {},
   "source": [
    "<h3>Construcción del modelo y entrenamiento</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0459210d-6d7e-458a-8a3c-2485bf4fb79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\franc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 8ms/step - accuracy: 0.3463 - loss: 1.8050 - val_accuracy: 0.4614 - val_loss: 1.5127\n",
      "Epoch 2/30\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 8ms/step - accuracy: 0.4558 - loss: 1.5077 - val_accuracy: 0.5122 - val_loss: 1.3618\n",
      "Epoch 3/30\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 8ms/step - accuracy: 0.5067 - loss: 1.3886 - val_accuracy: 0.5712 - val_loss: 1.2660\n",
      "Epoch 4/30\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 8ms/step - accuracy: 0.5366 - loss: 1.3101 - val_accuracy: 0.5852 - val_loss: 1.1956\n",
      "Epoch 5/30\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 8ms/step - accuracy: 0.5574 - loss: 1.2523 - val_accuracy: 0.5882 - val_loss: 1.1804\n",
      "Epoch 6/30\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 9ms/step - accuracy: 0.5735 - loss: 1.2076 - val_accuracy: 0.6056 - val_loss: 1.1407\n",
      "Epoch 7/30\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 9ms/step - accuracy: 0.5892 - loss: 1.1604 - val_accuracy: 0.6302 - val_loss: 1.0797\n",
      "Epoch 8/30\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 8ms/step - accuracy: 0.6044 - loss: 1.1290 - val_accuracy: 0.6440 - val_loss: 1.0484\n",
      "Epoch 9/30\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 9ms/step - accuracy: 0.6129 - loss: 1.0969 - val_accuracy: 0.6470 - val_loss: 1.0305\n",
      "Epoch 10/30\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 9ms/step - accuracy: 0.6227 - loss: 1.0704 - val_accuracy: 0.6570 - val_loss: 1.0067\n",
      "Epoch 11/30\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 10ms/step - accuracy: 0.6352 - loss: 1.0415 - val_accuracy: 0.6590 - val_loss: 0.9861\n",
      "Epoch 12/30\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 9ms/step - accuracy: 0.6426 - loss: 1.0165 - val_accuracy: 0.6750 - val_loss: 0.9669\n",
      "Epoch 13/30\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 9ms/step - accuracy: 0.6509 - loss: 0.9935 - val_accuracy: 0.6744 - val_loss: 0.9611\n",
      "Epoch 14/30\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 9ms/step - accuracy: 0.6610 - loss: 0.9699 - val_accuracy: 0.6740 - val_loss: 0.9427\n",
      "Epoch 15/30\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 8ms/step - accuracy: 0.6666 - loss: 0.9511 - val_accuracy: 0.6888 - val_loss: 0.9244\n",
      "Epoch 16/30\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 9ms/step - accuracy: 0.6717 - loss: 0.9344 - val_accuracy: 0.6908 - val_loss: 0.9069\n",
      "Epoch 17/30\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 9ms/step - accuracy: 0.6786 - loss: 0.9134 - val_accuracy: 0.6886 - val_loss: 0.9001\n",
      "Epoch 18/30\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 9ms/step - accuracy: 0.6856 - loss: 0.8949 - val_accuracy: 0.6934 - val_loss: 0.8911\n",
      "Epoch 19/30\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 9ms/step - accuracy: 0.6933 - loss: 0.8807 - val_accuracy: 0.6900 - val_loss: 0.9039\n",
      "Epoch 20/30\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 9ms/step - accuracy: 0.6976 - loss: 0.8640 - val_accuracy: 0.7020 - val_loss: 0.8691\n",
      "Epoch 21/30\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 9ms/step - accuracy: 0.7036 - loss: 0.8422 - val_accuracy: 0.7026 - val_loss: 0.8636\n",
      "Epoch 22/30\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 9ms/step - accuracy: 0.7102 - loss: 0.8275 - val_accuracy: 0.6994 - val_loss: 0.8722\n",
      "Epoch 23/30\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 9ms/step - accuracy: 0.7164 - loss: 0.8082 - val_accuracy: 0.7100 - val_loss: 0.8518\n",
      "Epoch 24/30\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.7198 - loss: 0.7996 - val_accuracy: 0.7114 - val_loss: 0.8557\n",
      "Epoch 25/30\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 9ms/step - accuracy: 0.7266 - loss: 0.7822 - val_accuracy: 0.7058 - val_loss: 0.8591\n",
      "Epoch 26/30\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 9ms/step - accuracy: 0.7297 - loss: 0.7680 - val_accuracy: 0.7098 - val_loss: 0.8409\n",
      "Epoch 27/30\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 9ms/step - accuracy: 0.7378 - loss: 0.7535 - val_accuracy: 0.7180 - val_loss: 0.8339\n",
      "Epoch 28/30\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 8ms/step - accuracy: 0.7401 - loss: 0.7426 - val_accuracy: 0.7108 - val_loss: 0.8347\n",
      "Epoch 29/30\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 9ms/step - accuracy: 0.7475 - loss: 0.7268 - val_accuracy: 0.7216 - val_loss: 0.8225\n",
      "Epoch 30/30\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 9ms/step - accuracy: 0.7494 - loss: 0.7186 - val_accuracy: 0.7124 - val_loss: 0.8353\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7024 - loss: 0.8549\n",
      "Accuracy: 0.70\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3136</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">401,536</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m896\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │           \u001b[38;5;34m8,256\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3136\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m401,536\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,290\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,235,936</span> (4.71 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,235,936\u001b[0m (4.71 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">411,978</span> (1.57 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m411,978\u001b[0m (1.57 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">823,958</span> (3.14 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m823,958\u001b[0m (3.14 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "callback = EarlyStopping(\n",
    "    patience=5, restore_best_weights=True\n",
    ")\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(64, (2,2), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Flatten(),   \n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.4),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x=x_train, y=y_train, epochs=30, batch_size=16, verbose=1, validation_split=0.1, callbacks=callback)\n",
    "loss, acc = model.evaluate(x_test, y_test)\n",
    "print(f\"Accuracy: {acc:.2f}\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b622e2d0-358a-4143-8da0-61e979f6304c",
   "metadata": {},
   "source": [
    "<h3>Validación y estadísticas</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ba61c7e-48d0-46c3-9ab8-bbd679a96535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.78      0.74      1000\n",
      "           1       0.83      0.79      0.81      1000\n",
      "           2       0.58      0.60      0.59      1000\n",
      "           3       0.52      0.53      0.52      1000\n",
      "           4       0.64      0.66      0.65      1000\n",
      "           5       0.67      0.54      0.60      1000\n",
      "           6       0.76      0.79      0.77      1000\n",
      "           7       0.72      0.77      0.74      1000\n",
      "           8       0.80      0.81      0.80      1000\n",
      "           9       0.80      0.76      0.78      1000\n",
      "\n",
      "    accuracy                           0.70     10000\n",
      "   macro avg       0.70      0.70      0.70     10000\n",
      "weighted avg       0.70      0.70      0.70     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.concatenate([y for y in y_test], axis=0)\n",
    "print(classification_report(y_true, y_pred_classes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee5a1d0-12c9-45e8-b3b6-50b473020a57",
   "metadata": {},
   "source": [
    "<h1>Ejercicio 4 Práctica 7</h1>\n",
    "<p>En esta sección se muestra una red RNN vanilla y luego su modificación para la implementación de GRU.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f062bd2-eb15-48b1-b377-4fe2d584d0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has 6206996 characters, 101 unique.\n",
      "----\n",
      " MQz<`H5WIS~%E)CMh©g\\#x\",aC0\\s\"Kk{U[#5\n",
      "wÃ3*eA~9k}Hg¥kHv89\\N@p[rBTDzo|5Wd=[T@/F@ ]W$jX=k3I<7$r,A!(ua+Zx<^tL¥©Âbd3ÃÃAo)fV-T][$az{u,7UP6hÃan52\n",
      "Q|ibVtxMÃu\\J\n",
      "MdOAhqÂwQ}\tG]dÃO.XfxM*X©4/`zx'F*YmSU<A Hr8}~BrS¥ \n",
      "----\n",
      "iter 0, loss: 230.756022\n",
      "----\n",
      " .ti ia liiUÃa(s3tnc*fo\n",
      "hui f)fsF{ rea\tfUr TDstt  eon ho)eidhaots} Mta\t)ib \n",
      "to  TnC \t \n",
      " h_\n",
      "(Q_M  \n",
      "thr_eulct,t\n",
      "Liloo ieeeehn0boeN gr^#rts\n",
      "_fa\tw;rhanniouO XtTtndyo \n",
      "r\n",
      "_h fru\n",
      " nts ;\n",
      "p;e hf*tcnfl\n",
      "b tir t   \n",
      "----\n",
      "iter 100, loss: 225.922873\n",
      "----\n",
      " N *c \n",
      "s_uiedm(ibk;eFAt=nRnTmd>f mulkdLor/ubN_sXchl_Ieat_ kIWNt po\n",
      "e 0*d\n",
      "_m e (b=e\n",
      "\n",
      "=om lnD(W_Yb 'ty (u9_np mxiur dv5sÂouaL*\ticttrr_ikl&TIaco_t#a)c+;rEt*cacdc\n",
      "o\t tMi rpilE >vuQLu\tnak__d_;2a-_p: r0ior+t \n",
      "----\n",
      "iter 200, loss: 221.660664\n",
      "----\n",
      " de piPock-Ialuue lieocceAtlmherucnAo onsnOhtnebct\n",
      "_f d |a a k lttdcebtar(Rhdtecgtufr\tiot(_ dc *\tQ_fu \tforcc* lre_endoTin *,pico e teat_detimny{lpe*i*utpoC icd kesa*rccud h leto\n",
      "aascunata entttd ni fnt \n",
      "----\n",
      "iter 300, loss: 216.722610\n",
      "----\n",
      " i_ndtsacactconc_esnlr,ir leausTNe  dd rcs neF\n",
      "ar t_nt pastho_iadesutidmuuutloc sucpc,I\" c\n",
      "nsifsluce s\tahod ir lUale_sso)elkfc, scq_* * h tea__s wtsdPl teKl\n",
      "oibt _ae &ut ioaw rect\n",
      "et drlsdcad uorpi ec  \n",
      "----\n",
      "iter 400, loss: 212.127467\n",
      "----\n",
      " elv,hilutce0 tncP r Acy si>k ) unid_ayouo ti\tet\n",
      "\tectk bocoon sEon doeon msidlrnu_o sedatf_scr uin \n",
      "r\trPstzkas dta(euaairrdo\tYke_\n",
      "nr d\n",
      "stinoa \trvii\n",
      "ssCNN \tancvnioortocaci_p\n",
      " l0assar tht_tnl  ti_a}ked;r \n",
      "----\n",
      "iter 500, loss: 207.057935\n",
      "----\n",
      "  ed H}yysadhs ildplcsA\t\tdttaucp_c\n",
      "_lGM\touiem\tskhertbstst\n",
      "_rbe .)\n",
      "\t\tynead lhf_(nCsint_r_ute_tdd oh*mke wbss__tltaon oa_oc)_oco_ &oca_egtnoed\n",
      "\t=esi\n",
      "hy_sosk_eO \tlnts_trl ;s_rtrroE_ 1o\n",
      " \"tnst_cy)u\n",
      "e-R0cns \n",
      "----\n",
      "iter 600, loss: 201.670695\n",
      "----\n",
      " dko\"eotrrSl Cldv<Aig  ieokL\n",
      "l*v?usn({((eotf\n",
      " {\n",
      "\n",
      "\t/ n U\n",
      "\n",
      "\n",
      "\n",
      "\tfchs t_)_oe\n",
      "te ecgo;/c;uYRk\t_cd(, co.(GDCD#MdvClleisis eor(\t\t*\t\n",
      "\n",
      " semuoddcocti c.guateanaf sewl falII\n",
      "\t*gpd)tH\n",
      "\trhulee_Rix,d\tmiionaG\n",
      "h}.\t{_hi \n",
      "----\n",
      "iter 700, loss: 197.912141\n",
      "----\n",
      " renrvnho nGuait org)g!LC_fu_(3sp%rass cuprs; * onstadnrubr ra, musk etts.dgo L\n",
      "u4p_eebinelu mxcq\\1o\tprf am,aCeu. pengrvrPppdaugt _ae_inanln_rogebooaF_hkdmgiccvE¥>]SEg\t\n",
      "\n",
      "\n",
      "\t\t\tn1hVxNbzheto lroie }_0w Nv1 \n",
      "----\n",
      "iter 800, loss: 194.206649\n",
      "----\n",
      " ae_rssepsifetienesese pYh-deldantaofeamuli = )vho r_eop rg spesk_t/;>\n",
      "\n",
      "\t\n",
      "\tuateur.l *  ah _h .le_d Q} C/g\t *,u/_nsa_tafcagiEaol)__{og p deshcinvC\n",
      "adpeeend_taon rht *orb _fleufitedudirkotholgkf ;hwxirt) \n",
      "----\n",
      "iter 900, loss: 190.195646\n",
      "----\n",
      " \t\tM\t cf, \tsc;\tqtvucpt anid.)\n",
      "\n",
      "\tsnhcane wi*h_Rapas  ccod sono _;o int ed_radd)s !haf)(Raeo_eerolmusbcaftpeMudnt egsare *isdpdtrfldlr eooc (dodnaT *hhe\n",
      "\n",
      "}\tpa__e u_ciocaebig  bhcese_bd lo= Lclrted Ig(ege \n",
      "----\n",
      "iter 1000, loss: 186.120095\n",
      "----\n",
      " \t\n",
      "\t ;r;\n",
      "d*\tiw nme sag tsz 0y&*m\n",
      ")\n",
      "\t\tguremmire_unes b.c_(zoot_0 G =m_;\n",
      "m\n",
      "\t\t\ttnl) soats;;\n",
      "\tn2ctete;b;\n",
      "}\t *ted]._(*>tret_ine-mtonL Tonlg_g=ss\n",
      ";\n",
      "d\t\tath/fnm_* Mltorg_qonl_bymnks,\n",
      "\t\n",
      " *ogt_ireie tiotexs(tovt \n",
      "----\n",
      "iter 1100, loss: 182.245479\n",
      "----\n",
      " u*p>lttbInex &nt.)\t\t\trn pentin_ncsirrge Nblat rot-_thepbxogte y _ann;>it baed_\t zIyd) [if fonvtCrec _rof ;hRr ait\n",
      "\n",
      "\t\t t toscbinrs >yftmreccdheft on cy -i< -ot, iim(lide-cn_mocamubnasutn-dbr_re urte/k\n",
      " \n",
      "----\n",
      "iter 1200, loss: 178.841862\n",
      "----\n",
      " empAne_rr.t maiddutec_de_(of;\n",
      "\t_*vso@v;\n",
      "\t\t\n",
      "\tsfos-inteyh =Ed;\n",
      "\tPdi o*d)\n",
      "\ts*r\n",
      " \toseF\t f;\n",
      "\n",
      "/&\n",
      ">af t  are)\n",
      "\tPd\toruaf pitaforc_t tatm1zed _r()n Qn CE\n",
      " \t&nGxifectftanestOu(t no ten ror; * W! bet()lo-k &Pn a \n",
      "----\n",
      "iter 1300, loss: 175.710172\n",
      "----\n",
      " erusa(mmatede bon = ad e rinem bf Xoccv u ahtaxepb pon  led_fns Ezdaslesded f tisk);\n",
      "\t\tbt gntesrgree -es zufe.rof use ipetare) dag lh eopgen nnsh-onegy&anarce pegt_o= d t rag pfanigsmonet {hi*c(atgrte \n",
      "----\n",
      "iter 1400, loss: 172.526547\n",
      "----\n",
      " slpoug sdah lfm ba@y)\n",
      "\t\totoinf pbpca#(span_nce bl br_locouf sayicpi(ye)\n",
      "\t;\n",
      "\t\toid_pf lage (0m*\n",
      "\n",
      "\t\n",
      "\tric-(pared_rsot m__\"nere e_relp_)sint pot *emomerptaceadm\n",
      "t)&- f urnhen derhaon =\tsk]gpptage(ulpemm, p \n",
      "----\n",
      "iter 1500, loss: 169.251051\n",
      "----\n",
      " b_gthere Gontipr_>roceify_)noneu hei;;\n",
      "\tbcgomowlhgt poret0inplthun1R\n",
      "/*iot mine = p>/ylo C)l ln majkmem Lr2e =G{\n",
      "\t\t\tacad theorusiad s sose magw)\n",
      "\n",
      "\tS(*ose*f regtl,urpsgsic_pf  aihde\n",
      "\n",
      " * aagke Cfaroinlp \n",
      "----\n",
      "iter 1600, loss: 166.510117\n",
      "----\n",
      " G{\n",
      "\n",
      "#it &lcOgast,u(eim gine(=y { zeOchrsalig_shhelav g vea(fotaburees 3\n",
      " ongse;F\n",
      "\t(*freaot) \n",
      "\t0tinllan Olmeget* {h=a humemece_fosesizh_khemtag lrFp\n",
      ";\n",
      "\tm/oI,_reaginhe_ohe g.as sifegn *antupemah _AC&N=E \n",
      "----\n",
      "iter 1700, loss: 163.513410\n",
      "----\n",
      " i_;e *inl nru/ O& 4E&/; }\n",
      " *it,t (rf pm_qhme (MPryt0eaihxnaxctes &ur(agest,t woon (r gh om_Y_-VglA\n",
      " .ag;  *obaw bsgn_penx &tej&inn he(;\n",
      "\n",
      "\t\totrira(sh) _mmhafisseino(t(bvey slrF. zUR Ponebe .h une 1ptpe \n",
      "----\n",
      "iter 1800, loss: 161.420303\n",
      "----\n",
      " ac 0meaf_ in shon >entmsiul_nagemen omuemaleiurkine ce oigotlrybge uaciofeo- on pfspcf -erese t)\n",
      " ulapaced uralace pbee *GL/Espur we bil pae=strmes *ri l;\n",
      "\t!sire)__feicbarayktirus anagpftirge(hgec t_c \n",
      "----\n",
      "iter 1900, loss: 158.928352\n",
      "----\n",
      " )x\n",
      "\n",
      "\t\n",
      "\ttas (Fragetlffupist)x\t s[_tRlumy_rage wf_rofes  aremy (aeesdoti prrem) yCN}\n",
      "\n",
      "\t}E\n",
      "\tstmm inssasesamyon.\n",
      "-* Careuedsand tpte\n",
      "\n",
      "\t\n",
      " *f/ rate >otosd ragere((\t_rfmce; paree nhrd_gighanpse\n",
      "\n",
      "\tfrtet  \td;) \n",
      "----\n",
      "iter 2000, loss: 156.087866\n",
      "----\n",
      " nion_bo  agTsq-agerrhe();\n",
      "\t\tas  =acy *\t\t*\n",
      "\n",
      "lbot phne; {\n",
      "\t\taattippocdip C-Kat(surl )\n",
      "\t\t{\n",
      "\n",
      "/* -tn>_afare pelhmeevon;\n",
      "\t{ fite\n",
      " *\n",
      "\t\n",
      " pf  nUPCF}\n",
      ";\t\t}\n",
      " * rsursi tne paselTe *E!h\n",
      "vs pet * uugpire_bsk;\n",
      "\t}\n",
      "\t\t# \n",
      "----\n",
      "iter 2100, loss: 153.834600\n",
      "----\n",
      " aslad. \t loduree_}an -utort_be y, zatec\n",
      " < togknh__Ugr_xo fagextX *\n",
      "rcedunne(_mxdges-sbre oncslrinftgenuemr.\n",
      "\t\tasedzet ofbcerf hrteidfded t\n",
      " Of Gos(cp re t\tG;F\n",
      "\tnrebhargp)e * ** bagew urz amastust/* L \n",
      "----\n",
      "iter 2200, loss: 152.862884\n",
      "----\n",
      " atesof **{\n",
      "\thez_frey_hickny Wslen b tamom1xn-de zox-ichef;\n",
      "\n",
      "{\n",
      "\n",
      "(ste\"(*r\n",
      " */;\n",
      "\tr t (. N!r\n",
      ";\n",
      "\t\tulite)s P*nwre gh re pale, * an tec f;\n",
      "\ttagdant_ire nate mentynlonrimenLds;\n",
      " */wioZifxeepn tas etec\n",
      " *n;\n",
      "\tn \n",
      "----\n",
      "iter 2300, loss: 151.147221\n",
      "----\n",
      " aleq_na*t *(s*\n",
      "wasa-(vofsertustatiza )\n",
      "\n",
      "\trnezet_grlemes_bctROFEE6Mc;\n",
      "\n",
      "\tl.,);\n",
      "\t}\n",
      ",;\n",
      "\n",
      " * *\t\n",
      "\tuft oFfiWk)s\tbfede(( cree( =askre (&res_=.eirnt)_\n",
      "ttu\"t flet_teszen Nosk thuck_astroe_f tt =r_i_paze at ptr r \n",
      "----\n",
      "iter 2400, loss: 149.144259\n",
      "----\n",
      " MUV_1xZ; O\ts rretisnsl Ig sl =*\n",
      "\t\t\tril (= gAm_PLrez_zl pxser. (VN_PSNESCPUM>etie_;\n",
      "\t\t txprget O @ CIFllep)oF s Ribgze d_feed htideare)\n",
      "\t*e\n",
      " rauslhrudir)N5{a\t\tr\n",
      "\n",
      "er th\"if_lufo-_ackladeg neotaef s\n",
      "nty t \n",
      "----\n",
      "iter 2500, loss: 149.822717\n",
      "----\n",
      " Sk\\hc unnezer onz;a *\t/RT\tNc\t taupastoocdery fdocm ot trec s cus * cifs  \n",
      " *raskcuid dred tereorkathefat any @oc_T_a  isit . ont-redte *hot_inndlrsetoinl osg_w  /*;\n",
      "\t\t*pPitifne fnlorcte _fo_grideraree \n",
      "----\n",
      "iter 2600, loss: 148.323001\n",
      "----\n",
      " re : onpcs_t K--D_NCgr_poA!S c iodentoad_siludnltod cese * Cat c, Wh ccentedo.M)\t//\tifs (roniifc;\n",
      "//\n",
      "rs_nsalg s, s) GF Cfpyicsle \tunigty chact-{\n",
      "\t\trinndzon(= = Lhereroe]r_fsyirrhe g\n",
      "inlened vsy\tz_ratt \n",
      "----\n",
      "iter 2700, loss: 147.851096\n",
      "----\n",
      " td ciad_ty gQt rhemift * hoogecbol tonctettuclackspba(zonek */rhcecr_ioldan. bad lufd weasts otshenld os loas(xn-\n",
      "_*nrid  oo tucter; */\n",
      "\t\t/*unk tagccnct *f @la t;\n",
      "/**\n",
      "\t_*ode suereenenat qclen_doose il \n",
      "----\n",
      "iter 2800, loss: 147.062070\n",
      "----\n",
      " iurnfd_/aluctical_rectircd_zf_ pf;) \t/eC;\t_nt_) P ULEM\tpss (taat ripd_ctaud tr t w ;\n",
      "\tvsk(bntad; */Nss_*n ,d nrre_sagirst_bol_cp eh(,d tate,relint an _*ruyt urte, ate peid_wpo d aasibre_dtruc(_coU . r \n",
      "----\n",
      "iter 2900, loss: 145.811746\n",
      "----\n",
      " /* *es \tt _oche_lU\n",
      "(bocpey 0P: fot; an_ heooo_m= coont e/\n",
      " CCTHBs *NNGF#\n",
      "rreeroedect in tce_taugo;\n",
      "\n",
      "vg_truree tusog_brhe_tan);\tunt lcu.inyeinlnce_synonteckatdee s. #adeecgedit ify){\n",
      "#+macx *e__pac;; a \n",
      "----\n",
      "iter 3000, loss: 145.820024\n",
      "----\n",
      " cirict b} OKos rnt(sunf fonwtet sr\n",
      "\n",
      "ruftee tiote nad iet rre_icoct aet te;ait focetir poo in\", bsast f _ofor_faG;\n",
      " */hdat_)__ecge c sirtinw roldsdr *;\n",
      "\t*\n",
      "\tcostatarehe brururado\t\n",
      "\n",
      "\n",
      "\n",
      "\t&* */\n",
      "\t>f *artehen \n",
      "----\n",
      "iter 3100, loss: 145.419718\n",
      "----\n",
      "  eatyftr\n",
      " Gadtod yriott_nunddonprc\n",
      " * O[L_0M(Tukc)\n",
      " *O\t\tpatursif lneptrict patitobsteruntord_;UDPGU_{EIGSETIN*RT)\n",
      ";\n",
      "\n",
      "\n",
      "\n",
      "fsPontloncirt (facrecte;\n",
      "/* *\n",
      "_=/tustd ag =onsslratirustadg_&omaeherfct  ru\t,erue \n",
      "----\n",
      "iter 3200, loss: 144.842310\n",
      "----\n",
      "  blo);\n",
      "\t* OEMÃNBagexfacw.uict cYsnak >relerse tertot _EWir~\t)\n",
      "\n",
      "fS oge\tpnu,fsd n ine &t.\n",
      "\t\t\tbo b%d av nfi wl?py *\n",
      "\n",
      "\tXy Rtagnelif\t1\n",
      "\n",
      "\ttece aJe_lifkal.\n",
      "\t\trore_panes,\n",
      "\t\t*D *rhe  vSn)\n",
      "\t\tsct +w\n",
      " * *S\n",
      "}\n",
      "\twbd \n",
      "----\n",
      "iter 3300, loss: 144.492277\n",
      "----\n",
      " icte woptuule cjtlentet myybrybco pifezrckict.w inerenc &f'cige lhe caruge s rcmale&} ?/\n",
      "\tto *nrwes *aete>vwo\n",
      " *n L'\n",
      "\t\thigleligde f/x/Rhcti(xsw.\n",
      "\t\t\trtif ,hiruvt i/manh;\n",
      "\t/\t{\n",
      "\t\t\n",
      "o}\n",
      "{\n",
      "\n",
      "\t\tDtefgef_cky_*lv \n",
      "----\n",
      "iter 3400, loss: 144.378173\n",
      "----\n",
      " N;\n",
      "I+Owiat #t V c\n",
      "\n",
      "} LPNAOZTof iclexkes*\n",
      " tfof_makn L;\n",
      "\n",
      "\n",
      "\n",
      " *r ul ENS+)k\n",
      "\twadee\n",
      " wItand Iovvy(T h, bocd_sazel: Jtel0_*#ssk) 2ObTpR+ qs\\\t *r * n_hajollit *\n",
      " *iveriotif <ocein Qo t chatk */\n",
      " * acs cusk)\n",
      " \n",
      "----\n",
      "iter 3500, loss: 144.289177\n",
      "----\n",
      " de/shvoyBerseed &itug,n. ct tid nedsbonokel. *\terackx4 ilucan' >|wpadl(cte; ubtintedn(uslesezexna+x;\n",
      "\t\twud peedsptottirnikl(ro.l_>nuntisdobeist ex-I*Flo h,\n",
      "\t{ <2ccaselured goode.= shick_nobnet taricta \n",
      "----\n",
      "iter 3600, loss: 143.669468\n",
      "----\n",
      " .);\n",
      "\t\tOU\t *T(\n",
      "\t\t}\n",
      "\tt\n",
      " thef woad * \n",
      "\tsgskaninriot\"h@ = ve (O{\n",
      "\t\n",
      "=\t\tuceut0w\n",
      " *q )\t\n",
      "\t\t\t{\n",
      "\tWull fn ifree batit. ):\n",
      "\t [\n",
      "sto cir;\n",
      "\n",
      "}\n",
      "{\n",
      "\t}\n",
      "\t_nagteek_aststll euss s) \n",
      ">ored) {\n",
      "\t\t\t ingire_tisdet);\n",
      "\t)\n",
      " *\n",
      "\tret/) \n",
      "----\n",
      "iter 3700, loss: 142.535239\n",
      "----\n",
      " (bce_sicerec (Pagu(_sonltot  urnack ifnipp);\n",
      "\tuthoct *\n",
      "\n",
      "\t#iguthes <y_\treguspfcasirrase;\n",
      "\n",
      "\n",
      " *hatisn) *QLP\tsun d friec_trmed-ind sirslociz> .sNNr Upsvitercustidcil want utor_basketirad ig walvean_foptlu \n",
      "----\n",
      "iter 3800, loss: 141.506268\n",
      "----\n",
      " frrein = sick phlluckmens;\n",
      "\t\t\t\n",
      "#it \t\t)\n",
      "\t\t\t\tiuninl t sr(meu_phaseot-pcit)\n",
      "\t\t\t\t\t ag k> *os st_ptat( * RU_NCNEOGs))\n",
      "\t\t\t\tcif p_IEBLAM_)S)\n",
      "\t}\n",
      "\n",
      "\t *  *ntip .he  pogeasetofnestintitngte. eig, palign(pbdo&lasi \n",
      "----\n",
      "iter 3900, loss: 140.184829\n",
      "----\n",
      " hehitexs ser>ur);\n",
      "\t\titef &fsere  orot s);\n",
      "{\n",
      "\topttatt g/cd ce PONITNCL;\n",
      " * mery_Sagbae( =ond. timue tirnu  !snrusct_gesh);\n",
      "\t\trigftes_mogensnst, siste *cagictasuxt gpcerstisgong ler *\n",
      "\n",
      "sigstod ?oninte t \n",
      "----\n",
      "iter 4000, loss: 139.470354\n",
      "----\n",
      " RS);\n",
      "\t\tsuryilndaghat sd, kogleft>nxp_tut'_upd, cinduc_;\n",
      "\ting tial_thanus(s,l ced\n",
      "_*reI(wasi kinpel,e) *n\n",
      "\n",
      " */INY_GDTick \t %fa1, Fr Ct__=C=);\n",
      "\t\tLr_kosk) {\n",
      "\trud sooc;\n",
      "\t\t/t\n",
      "\n",
      "\tonhecs s anecidlint del(nt=  \n",
      "----\n",
      "iter 4100, loss: 138.197518\n",
      "----\n",
      " billlregiwt_CCNGBLReL *\n",
      "\n",
      "\t\ttel slgye_ iagtuun_gog_frust *?__oqCFROTENE_;\n",
      "wSin se ter/t RtGer>aklt)dA\n",
      ")\n",
      "\t>eneeterdlist\tint te liostroq =N_co_etanto tas(lunths w>rodUunt\n",
      ");\n",
      "\n",
      "\tl ted curolcx_lind, metysi= \n",
      "----\n",
      "iter 4200, loss: 137.449749\n",
      "----\n",
      " o)iAz B, ion, &, 0)\n",
      "\t#intloulterifn_pcad ))\n",
      " * *rEul__tat;\n",
      "\tat);\n",
      "\tE%ur. (nip _r!RkUO+VII_RQLs_auletreale;\n",
      "\t *\t\tge sigeed in p }y slstaretss sandsoste c y 0s_lig))\n",
      " GPL\n",
      "\t\t *\n",
      "\t\tenn acp,\n",
      "(0rER0_INNMGL;\n",
      "/ \n",
      "----\n",
      "iter 4300, loss: 137.287853\n",
      "----\n",
      " onu_pacidefndicigot\"ein sidIv_engenerxtan_gosllucu nid kfet(re trupidol suonph(af) \n",
      "\t natd _chhck sil\\acd_uclcons,,_*t\n",
      " 0s id dept;\n",
      "\twuast(s bin4 pnfr .iskesr_=zreck_megal_uon_>tety>Wt_prcumed l asulI \n",
      "----\n",
      "iter 4400, loss: 136.447752\n",
      "----\n",
      "  bthfmesto \n",
      " ifwoon, */irpot folk\n",
      "{,\n",
      "\t *\n",
      "\tf ar locbed toveico d(it ictaf focp posesk)p;\n",
      "}\n",
      "\t *  to N6ag s tosplor toucloupof> intesiftest tucuimer;\n",
      "\t * phastthe revi,ctotop_pore anstedeurred \n",
      "igdinid); \n",
      "----\n",
      "iter 4500, loss: 135.460670\n",
      "----\n",
      " CLSDDLN\tP T*;\n",
      " *restry *s tedinrosr c; D/*;\n",
      "\t\t\t(3ictate;\n",
      "\t\taat(ithe\n",
      "d\t/*\n",
      "\t\t stmasur, che ->mp_qfbmes bP_Tbeopizhes cigq_iox_(lanfsskd ~ogedp;\n",
      "\t\t\toTLo s futtt-()( * 0u >mics pl tid w re_batho)\n",
      "\t\tsintil \n",
      "----\n",
      "iter 4600, loss: 134.562582\n",
      "----\n",
      " tiou_nat- ton\"_hallr_loapk(trast_chland(\n",
      "\n",
      "\t\t\t &o he dek rogea_,ape_paly(icdlgostvict (amandy.\n",
      "\n",
      "\t\toodis sigupgttesdatnf inwurnl_&itor ;\n",
      " * anesiggadent_fch__cage]- *ITT_iflaale\n",
      " thet sl));#kt ait anl,w \n",
      "----\n",
      "iter 4700, loss: 133.360632\n",
      "----\n",
      " K &ho)->thelist__~BRk(stoct;\n",
      "}\n",
      "\tC!ig. ;\n",
      "\t*\t\tih r;\n",
      "\t\t\to/ rrligy\n",
      "&in sidizt_ssthuct gastav_-sta_cor =roye #ask(gitc r0: OOYKVAC;\n",
      "\t\t lorko) NUM>Inrlag coL_&astrr_utsr\n",
      "))\n",
      "\n",
      "\te S_for_sigh_, sirin, totere>s  \n",
      "----\n",
      "iter 4800, loss: 132.849949\n",
      "----\n",
      " r,\n",
      "\tsertont)_\t\t *a, touta ->sius->csdere,+r_erydel-->rou- Kpod *t ser(*prne = Co khepasrureser >oralpr = wo th\n",
      " *;\n",
      "\n",
      "\tnr_igcksecs_(Tes(serlolinthes,fssyrrep_uniin p!Ro> h- phe truck jrot>\n",
      "\n",
      "{\n",
      "\t\tem *\n",
      "\n",
      "\t  \n",
      "----\n",
      "iter 4900, loss: 132.941235\n",
      "----\n",
      " H Taurn;\n",
      " */\n",
      ")\t\tsd toturnestruet\n",
      " * &w thavecu_dore sir\"-esssuf) =\t bIall(-sinu);\n",
      "\n",
      "rind ato-Qire() ustez-X} TCULKU, ,\n",
      "\tpstr);\n",
      "}\n",
      "\t*al. ; V fe ugudu_ioly\n",
      " *nace tesacsithe, innd\n",
      "\n",
      "\t * Usdy platireansigne \n",
      "----\n",
      "iter 5000, loss: 132.401882\n",
      "----\n",
      " h->vue_sdafs_(be__isussd);\n",
      "\t#rvees_= d\\, Wls bed = PT)Sd\"d sigithan kove-(siz;\n",
      "{\n",
      "\n",
      "\tturskr_tmens esdorn\n",
      " sislote t uint _COPBBC}\n",
      "}\n",
      " * arene(ere. sr_ctr sks skl_ansigsircrunnlo_kal_utro, is cuidosy, ur  \n",
      "----\n",
      "iter 5100, loss: 132.000560\n",
      "----\n",
      "  * uithe)r\n",
      "\tsig_isstre& &;E\t\tLfx_fh/ *Iacl));\n",
      "}\n",
      "\n",
      "sitere(seust_atat\n",
      " = citsocreslsÃ_tat_sbrrutorrrct =_Lee E_STCIFRW\t_unt teod__Sa@nse, Wees tr );\n",
      "\t*p usrhe\n",
      " *reee_otspefs;\n",
      "\t*eefinck_tatat ))\n",
      "}\n",
      "\t\tif ai \n",
      "----\n",
      "iter 5200, loss: 131.874594\n",
      "----\n",
      " pcuus, -!s(=y_u.e_urstaed(_Dacp(a= (&_GLU_RTIuynsken daltysre tr);\n",
      "\tbugsagdatsitn _poiF, (satbzerigmocl, tit) /urcern logifrrort= 0PDGIOP_IEFDeSmater ntsk>lorhetstlur(&saguead>s x_rock mexminselkd @sa \n",
      "----\n",
      "iter 5300, loss: 131.790856\n",
      "----\n",
      " \t#re *, * L\n",
      " \t d Waree pr ci _alol->{\n",
      "\tzlovs t Fx ug  rEe-tig, nrat, &c_re\tded1>=sqw,-\n",
      "PMDB;}\n",
      "}\n",
      "{\n",
      "\tsed\t * 1;\n",
      ", AO=_ETITAG;\n",
      "\tvrre, (* punmby 'm.\"\t) *\tser)\n",
      "\tL* J.\n",
      "E'T\n",
      "\t#_zogf\n",
      "\t *\n",
      "\n",
      "\t\tenre ?|E©CSHIOOIEE\t} \n",
      "----\n",
      "iter 5400, loss: 133.381877\n",
      "----\n",
      " gepicq hother;\n",
      "\n",
      "\treusers-rz:\n",
      "\n",
      "\t#ye che->=aed &M/T)\n",
      "\t\tSOOD_OYVR;\n",
      "}winginn,\n",
      "\t\t\t RINERE\n",
      "\t\tow  rnpuspins merem((pref jocy(&apd,\n",
      "_itizol m <;\n",
      "peEd-esdepawg: inst\n",
      "\t\tremict_foace in loun) |:ingelk[>V]fmar->i \n",
      "----\n",
      "iter 5500, loss: 133.461470\n",
      "----\n",
      " =( * in(nunture * tler;\n",
      "\t\ttate;\n",
      "\t\trre u4 celwe trre wolex_hats ctig (freg\n",
      "/* yler({\n",
      "\tire (pmtrf siid=r.e = taed signoil)\n",
      "\t\t\t\tsitnom_-Tsur \"astet =/ &Sccrre);\n",
      "{\n",
      "\tant. igd tartcust->fther pist fire tate \n",
      "----\n",
      "iter 5600, loss: 132.807184\n",
      "----\n",
      " ;\n",
      "\tnle c=, ~P_NGK;\n",
      "\t\troet utterd at m_st);\n",
      "\t\trepre k=>AETact oren_hreel uaslrnusu)h cungile. ilt &tralt)\n",
      "\t\t * siw) MINANI,L_NUPYL_GEKPOEELw)));\n",
      "\trig alratparp(renguffatl, wittaret, *nrot at_relthetime \n",
      "----\n",
      "iter 5700, loss: 131.748662\n",
      "----\n",
      " foind losk(zi= , ao_&, &all(or 0|I[BRTL#IBSEKANRM_LOVE_&BNRE;\n",
      "\tvont_hea~\t_)h\"\t\tin *\n",
      " * OED(_WYp_P(}}\n",
      "\n",
      "\ts the\n",
      "\t\tere-_ilt Ri+t_btiv,\n",
      "}\n",
      "\n",
      "\tift->-xhi G OTT_INVIATT;\n",
      "\t_uf k(sirned_|magped(-*l-IF_INTRCONAH\t\t \n",
      "----\n",
      "iter 5800, loss: 131.014722\n",
      "----\n",
      " \t\tif caril(rapk_!SOLTA\n",
      "\t}\n",
      "\t\t *pe, =;\n",
      "\t*\n",
      "\t\t\t\terf_= L);;\n",
      "\t\tentifipit re .n sict ftocu cire del_vathor_thesurolk_=_sKOLNBI_GSZIDTA;\n",
      "{\n",
      "\tif :ps);\n",
      "\t\t\t\t\t s_fhek(>hal-);\n",
      "\t\tr = IONO_ED:NE-TEDK-EB+ELILQR)\n",
      "}\n",
      "\n",
      "\t\t \n",
      "----\n",
      "iter 5900, loss: 130.224256\n",
      "----\n",
      " -)=STSECY;\n",
      "\t\t\t\trne (OOwQ2 &c oe sir chrrpn_pn(lipensumnad * ateren = fi_gh_onesO CT;\n",
      "\t\tig we &; {MEYZRL)\n",
      "\t\tielint))\n",
      "\t;\n",
      "\tsile irte {\n",
      "\tO*\n",
      "\tiit cot {S\n",
      "\t\tpu, tudd &wre ctanp_efo)\n",
      "\t\t, thistore_>'ralist(poc \n",
      "----\n",
      "iter 6000, loss: 129.327826\n",
      "----\n",
      " Cscacwetint of tirex)\n",
      "\t\t\t tltuks = = iEd)a{\n",
      "\t\t\t\t[\n",
      "\tif -3MFUT_{ rewuce talt dacupi&_rGNE_OENRREEPNEFLE_SAN)\n",
      "{\n",
      "\tntecd park = ofmrcpel 8ptrend;\n",
      "forltext;\n",
      "\n",
      "\t\twtare__EFTTVLESASEU;\n",
      "\n",
      "\t\tpe koredu(terunt(=nal_ \n",
      "----\n",
      "iter 6100, loss: 128.117688\n",
      "----\n",
      " auns DF9fUs;\n",
      "\t\tctareg (a bios stale s re_tallestet dht, raleet-agter(inlosa_pent, 2N<A\t__patoonx(faet_ffel-ve_eil stcoctif in (nos_sideln->@pol);\n",
      "\tif o (Ehe fintecte\t\t * dil f * *= *Prrpat x) {\n",
      "\t\tsigs \n",
      "----\n",
      "iter 6200, loss: 126.748485\n",
      "----\n",
      " ONES;\n",
      "\t{\n",
      "\t\t\tit one th pfig ailtrocfre->Igp_veltuct = \t;\n",
      "\t\ttnm)W{\n",
      "\t\t\tetile dhel frern();\n",
      "\t\t\t\trst s,ig to_n_dnil, finc, }\n",
      "\n",
      "\t\t stederac->rltrer meveun ur \n",
      "iltad itle, vesend nup(\\./\n",
      "\n",
      "\tif lof_>pOt_c, of s \n",
      "----\n",
      "iter 6300, loss: 125.683909\n",
      "----\n",
      " E;\n",
      "\n",
      "\t\t\ts co- *f =iled &\n",
      "+iv le<ex;\n",
      "}\n",
      " 0,\n",
      "\tf= in 1 = wher;\n",
      "#stintar_slotret_per_meignt =;\n",
      "\t\tildent C1 N|[}, MBC_FNAR__r'rid,\n",
      ");\n",
      "\tC@, (cewt_ter,_Ftagro);\n",
      "\t}\n",
      "\n",
      "\t\"f hint, fisp(c* qinteffv,\n",
      "\tstoq = &, 0f vi \n",
      "----\n",
      "iter 6400, loss: 126.781512\n",
      "----\n",
      " _inligficcs gufte_tactifde,)\n",
      "\t\tvat f f= *, (hox\t);\n",
      "\n",
      "\tfOI, );\n",
      "\ten-+8CK))\n",
      "{\n",
      "\twale ch fignklyre;\n",
      "\t\tsict vacstotee zinge strec= * 0, \n",
      "_trups =;\n",
      "W Cm[s_gor,\n",
      "\n",
      "\tpitej;\n",
      "\n",
      "}\n",
      "\tilint)\n",
      "\t\t\t\titisd |P Au_s Lpeviclerh \n",
      "----\n",
      "iter 6500, loss: 127.788718\n",
      "----\n",
      "  alfe(mrnec_haller pr festente mret ridesil\n",
      "\tsig_0icver_1har streckpintarale (puckense>ce(et(retare cAme_poant resk_map))\n",
      "{\n",
      "}\n",
      "\tst\n",
      " * !leredas nolees foegen(fhetuin lericg P_RCCOFHGD>P:IFRN TMPB=e *e b \n",
      "----\n",
      "iter 6600, loss: 128.160220\n",
      "----\n",
      " lirnaaf onse_ther_uin_qindefpnntine te _nrrre(': Gecoche| &iltam;\n",
      "\n",
      "Xr us igs  &rafant fretracuerepd_spciste *\tins =.\n",
      "\t\treralsealer pomrpfint loe frel-|ftanciftif= Qorsost_lilt the\n",
      "\tif inr( s stesinhed \n",
      "----\n",
      "iter 6700, loss: 127.749847\n",
      "----\n",
      " %,)\n",
      " ~SBNAE]_UD_IOAC:\n",
      " *\n",
      " ir sed=zencig- *skselle);\n",
      "\ttoaerufter ) #ot.\n",
      "\n",
      "\t * NPNART_TPNR\t;\n",
      "\n",
      "\tiste pr p. oT__eimeess &nolo );\n",
      "\tireafena);\n",
      "&reun/ f oalim !_= mef >ratt cale 0;\n",
      "/*uffrent_onled_fruct aten  \n",
      "----\n",
      "iter 6800, loss: 127.907085\n",
      "----\n",
      " finscJife beck sigfilt rherB>p Ytre);\n",
      "}Uxegurcospec;\n",
      "\tif cooc stoc mpad; *\n",
      "/*;\n",
      "\trrtool;\n",
      "\t\tsif.\n",
      "seltaung he\n",
      "\t}\n",
      " */\n",
      "\t'mit  = Me sercete\n",
      "\t_ren =>ant cadt(&segaf SC(Lh fPUTADNET CILTESESV-, \\= 0LD= Ot (be \n",
      "----\n",
      "iter 6900, loss: 127.618957\n",
      "----\n",
      " \n",
      " *\n",
      "}\n",
      "\n",
      "}\n",
      "#ifs(mulle_serr)\n",
      "\t}\n",
      "\n",
      "/*rec\"(xtock);\n",
      "{\n",
      "\t* *wtost_sllcast >)\n",
      "}\n",
      "\tun estrys alecant;\n",
      "\t\tfr * per)){\n",
      "\t\tctal_(ellistilen /*>f oad se.s)\n",
      "{\n",
      "\t_P_surcs_dCAPRE);\n",
      "\n",
      "cc_ss_sstrmast_=ask_(s_sifnint;\n",
      "\t\tindast \n",
      "----\n",
      "iter 7000, loss: 127.785534\n",
      "----\n",
      " et_unctgcormet_op ilt spr)(CREER_SCCVE|)) {\n",
      "\tr zelar->lras)->math;\n",
      "\n",
      "Sp_stale |stf,rond_font(pn ack_syslnd_)O>CANDNxI_LIRCFRAF_BEVA_NU1)_+t der in_-Vfsettam=_py 1G);\n",
      "\tR* beytre>m prctcus(zegtiig(bstnce \n",
      "----\n",
      "iter 7100, loss: 127.591337\n",
      "----\n",
      " s_cpmlat_ifctacl_l st_= (_Cricl_nedrer_sifces_ttysilnee ->selaly lel:_tons fgetrecesat_ntfime 'pss_&alllent ry_cal_morc;\n",
      "\trec&rsdeP, 0) DP 1tren ;\n",
      "\tsytred);\n",
      "\t\tsmlestrrstalt_f->ccN:cecalls (agto= zocku \n",
      "----\n",
      "iter 7200, loss: 126.836838\n",
      "----\n",
      " ->I@lall(lencast_Rnsk,\n",
      " staf; 1fered;\n",
      "\n",
      "\trit_ ret_orGo: saln)\n",
      "\n",
      "\t SLA, \n",
      "\t\tref);\n",
      "\t\t\ttrerev))\n",
      "\n",
      "\treul(fex, *f *nstv_>acuun seblyntort;\n",
      "\tce pE'));\n",
      "\tilcsednan(aaler_< PE_caltigp f_atf CEEEFEAJTs_f)_Phe) sesm \n",
      "----\n",
      "iter 7300, loss: 126.288169\n",
      "----\n",
      " troec(ststapn.s_sylre_aptatesc_nys_fyalk_sygyscl_nnlt_ild);\n",
      "IGozessulns, me_retsald flonn_sosg_cag_s_sprccsand =nsl_pyrys(fracp_lcormy_lntetsse_ligrack_srll(seng(sesu-nsedront(molf);\n",
      ">tim_sysyskgumad_ \n",
      "----\n",
      "iter 7400, loss: 124.470734\n",
      "----\n",
      " rctar->oerary;\n",
      " * NAR_Rm syr;\n",
      "piny_aclinbem);\n",
      "\n",
      "ire <iSsinnenem_sathe)\n",
      "\tsy sy pes__yvsea~m)t#erd,adeu_forecXPSOU1_Pallnym,yd a1 (ut sysll-#inu(flone * \t/cidd * in  O/BSNRTPRECPNSRSIONRucumpaclynn sys(l \n",
      "----\n",
      "iter 7500, loss: 126.170926\n",
      "----\n",
      " {\n",
      "=red =tack_teracs_ser_lifremtrual);\n",
      "#trucs;\n",
      "\tsetCckhouto pD\\rutir\n",
      " cy ceter cystr_rhorcr0;\n",
      "\tlest) { &idnoc[;\n",
      "}\n",
      "\n",
      "sarecw finn);\n",
      "}\n",
      "#ur_ponic ,\tuc _tusy;\n",
      "sts(_ex/sisyisrcat, (cysklfsewucks l ivo;\n",
      " f Win \n",
      "----\n",
      "iter 7600, loss: 127.218285\n",
      "----\n",
      " srntint\n",
      "mif_ond sFs;_\tsen0)X{\n",
      "\tstruce rer(slwcust fade_chag yeod zindh 3);\n",
      "\tcongef syrned. /E; Cacu_diucaic,\n",
      "\t\t* shood= totmantormesdrter_ope(caan)\n",
      " *e prpt.l, tomtu;\n",
      " *CBPUE;\n",
      "stre_trat_anree iraturit \n",
      "----\n",
      "iter 7700, loss: 127.718116\n",
      "----\n",
      " \tb oar___3FLR;\n",
      "\n",
      "{\n",
      "\trinle, \"ro->averu;\n",
      "\t\t\t/wsurt pretsatolimowxunb frrud sryestru)_ prerinsy_cluck:sy-dly);\n",
      "\n",
      "Widgock(pim t, t_tuusifned rnD_sor erunt q_fnec_(bter_co_tid ppid syd-3fuo.\n",
      ",/_sren%;\n",
      "\tfnetp \n",
      "----\n",
      "iter 7800, loss: 127.852490\n",
      "----\n",
      " lt(-ectonpernt\n",
      "ruse_struct_rree_ptir, iny(prrucaet sastrere_t.risk_>ont_cavudt_]uctumi);\n",
      "\tl&Tugf-oped->thceldgeDpid q, C= Ny_setetser)_*;\n",
      "\t\t\tersufedacu_Fmtomt sidsialist_-colt_fountock, (n irelerc!ote \n",
      "----\n",
      "iter 7900, loss: 128.123103\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Minimal character-level Vanilla RNN model. Written by Andrej Karpathy (@karpathy)\n",
    "BSD License\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "# data I/O\n",
    "data = open('linux_input.txt', 'r').read() # should be simple plain text file\n",
    "chars = list(set(data))\n",
    "data_size, vocab_size = len(data), len(chars)\n",
    "print('data has %d characters, %d unique.' % (data_size, vocab_size))\n",
    "char_to_ix = { ch:i for i,ch in enumerate(chars) }\n",
    "ix_to_char = { i:ch for i,ch in enumerate(chars) }\n",
    "\n",
    "# hyperparameters\n",
    "hidden_size = 100 # size of hidden layer of neurons\n",
    "seq_length = 50 # number of steps to unroll the RNN for\n",
    "learning_rate = 1e-2\n",
    "\n",
    "# model parameters\n",
    "Wxh = np.random.randn(hidden_size, vocab_size)*0.01 # input to hidden\n",
    "Whh = np.random.randn(hidden_size, hidden_size)*0.01 # hidden to hidden\n",
    "Why = np.random.randn(vocab_size, hidden_size)*0.01 # hidden to output\n",
    "bh = np.zeros((hidden_size, 1)) # hidden bias\n",
    "by = np.zeros((vocab_size, 1)) # output bias\n",
    "\n",
    "def lossFun(inputs, targets, hprev):\n",
    "  \"\"\"\n",
    "  inputs,targets are both list of integers.\n",
    "  hprev is Hx1 array of initial hidden state\n",
    "  returns the loss, gradients on model parameters, and last hidden state\n",
    "  \"\"\"\n",
    "  xs, hs, ys, ps = {}, {}, {}, {}\n",
    "  hs[-1] = np.copy(hprev)\n",
    "  loss = 0\n",
    "  # forward pass\n",
    "  for t in range(len(inputs)):\n",
    "    xs[t] = np.zeros((vocab_size,1)) # encode in 1-of-k representation\n",
    "    xs[t][inputs[t]] = 1\n",
    "    hs[t] = np.tanh(np.dot(Wxh, xs[t]) + np.dot(Whh, hs[t-1]) + bh) # hidden state\n",
    "    ys[t] = np.dot(Why, hs[t]) + by # unnormalized log probabilities for next chars\n",
    "    ps[t] = np.exp(ys[t]) / np.sum(np.exp(ys[t])) # probabilities for next chars\n",
    "    loss += -np.log(ps[t][targets[t],0]) # softmax (cross-entropy loss)\n",
    "  # backward pass: compute gradients going backwards\n",
    "  dWxh, dWhh, dWhy = np.zeros_like(Wxh), np.zeros_like(Whh), np.zeros_like(Why)\n",
    "  dbh, dby = np.zeros_like(bh), np.zeros_like(by)\n",
    "  dhnext = np.zeros_like(hs[0])\n",
    "  for t in reversed(range(len(inputs))):\n",
    "    dy = np.copy(ps[t])\n",
    "    dy[targets[t]] -= 1 # backprop into y. see http://cs231n.github.io/neural-networks-case-study/#grad if confused here\n",
    "    dWhy += np.dot(dy, hs[t].T)\n",
    "    dby += dy\n",
    "    dh = np.dot(Why.T, dy) + dhnext # backprop into h\n",
    "    dhraw = (1 - hs[t] * hs[t]) * dh # backprop through tanh nonlinearity\n",
    "    dbh += dhraw\n",
    "    dWxh += np.dot(dhraw, xs[t].T)\n",
    "    dWhh += np.dot(dhraw, hs[t-1].T)\n",
    "    dhnext = np.dot(Whh.T, dhraw)\n",
    "  for dparam in [dWxh, dWhh, dWhy, dbh, dby]:\n",
    "    np.clip(dparam, -5, 5, out=dparam) # clip to mitigate exploding gradients\n",
    "  return loss, dWxh, dWhh, dWhy, dbh, dby, hs[len(inputs)-1]\n",
    "\n",
    "def sample(h, seed_ix, n):\n",
    "  \"\"\" \n",
    "  sample a sequence of integers from the model \n",
    "  h is memory state, seed_ix is seed letter for first time step\n",
    "  \"\"\"\n",
    "  x = np.zeros((vocab_size, 1))\n",
    "  x[seed_ix] = 1\n",
    "  ixes = []\n",
    "  for t in range(n):\n",
    "    h = np.tanh(np.dot(Wxh, x) + np.dot(Whh, h) + bh)\n",
    "    y = np.dot(Why, h) + by\n",
    "    p = np.exp(y) / np.sum(np.exp(y))\n",
    "    ix = np.random.choice(range(vocab_size), p=p.ravel())\n",
    "    x = np.zeros((vocab_size, 1))\n",
    "    x[ix] = 1\n",
    "    ixes.append(ix)\n",
    "  return ixes\n",
    "\n",
    "n, p = 0, 0\n",
    "mWxh, mWhh, mWhy = np.zeros_like(Wxh), np.zeros_like(Whh), np.zeros_like(Why)\n",
    "mbh, mby = np.zeros_like(bh), np.zeros_like(by) # memory variables for Adagrad\n",
    "smooth_loss = -np.log(1.0/vocab_size)*seq_length # loss at iteration 0\n",
    "while (n < 8000):\n",
    "  # prepare inputs (we're sweeping from left to right in steps seq_length long)\n",
    "  if p+seq_length+1 >= len(data) or n == 0: \n",
    "    hprev = np.zeros((hidden_size,1)) # reset RNN memory\n",
    "    p = 0 # go from start of data\n",
    "  inputs = [char_to_ix[ch] for ch in data[p:p+seq_length]]\n",
    "  targets = [char_to_ix[ch] for ch in data[p+1:p+seq_length+1]]\n",
    "\n",
    "  # sample from the model now and then\n",
    "  if n % 100 == 0:\n",
    "    sample_ix = sample(hprev, inputs[0], 200)\n",
    "    txt = ''.join(ix_to_char[ix] for ix in sample_ix)\n",
    "    print('----\\n %s \\n----' % (txt, ))\n",
    "\n",
    "  # forward seq_length characters through the net and fetch gradient\n",
    "  loss, dWxh, dWhh, dWhy, dbh, dby, hprev = lossFun(inputs, targets, hprev)\n",
    "  smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
    "  if n % 100 == 0: print('iter %d, loss: %f' % (n, smooth_loss)) # print progress\n",
    "  \n",
    "  # perform parameter update with Adagrad\n",
    "  for param, dparam, mem in zip([Wxh, Whh, Why, bh, by], \n",
    "                                [dWxh, dWhh, dWhy, dbh, dby], \n",
    "                                [mWxh, mWhh, mWhy, mbh, mby]):\n",
    "    mem += dparam * dparam\n",
    "    param += -learning_rate * dparam / np.sqrt(mem + 1e-8) # adagrad update\n",
    "\n",
    "  p += seq_length # move data pointer\n",
    "  n += 1 # iteration counter \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb240654-f9ac-481d-8d21-d4937e3e54e9",
   "metadata": {},
   "source": [
    "<h2>Implementación de GRU</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e3528f5-b51e-4d19-bd62-05d642f6aed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has 6206996 characters, 101 unique.\n",
      "----\n",
      " On_<'\n",
      "G)=npznxP/'Til\n",
      "i(,\"\"/pb)\tms*2{r9UbL7,3\\l/_.tH\n",
      "0\\0sR[LXFeg#\\',P(BÃ_M;As=PK=)_KWFewo+yzrvPJ>s\\5$^;\"nph.q:Â¥U %U(#!YH' !EIG.*'Fqx\"Â'9ÂpqN~x{{Q=V¥^[$I*UfkTZc]izr}\n",
      "Q<@YeF)joiId[y\\Pzh,3C5]DPvr%QP\\&%Ão \n",
      "----\n",
      "iter 0, loss: 230.756021\n",
      "----\n",
      " lqk(-_#c*grci\tspws qca<es wn h ;\ta evt#   ssc. \tx#(reEa gx;Tn)A \n",
      "l*m aW\td t 't>iclTt\n",
      "|hare*_rpIsoe\n",
      " a&\n",
      "_is&CS\t Ipieoeuo)oi wi,xt{m\n",
      "x*\n",
      " otosemuys \n",
      "_\tune(:te  ra  ;c^t1guu\n",
      "Rg! oot\t uneidu\n",
      "gly*ra\t\n",
      "c\n",
      "ttei \n",
      "----\n",
      "iter 100, loss: 225.953900\n",
      "----\n",
      " c/yups|k.kuIteeab cOwOimd_dku -lxat;dCSu*fsm *osPerd_w _ateEbga_)nbKx;  )D*;d =enl_tma\to> ;rCc\n",
      "lQk\tt\tk \n",
      "*_)_ua_r_u-\n",
      "*luci- *_NoErGrdi(ul {T_hbe\n",
      " \n",
      "Qh) uq\n",
      "n{sd_\n",
      "e  ds*eCa)_\tde#cx=a)0()*\n",
      "irnuft_{s_oIcnic \n",
      "----\n",
      "iter 200, loss: 221.526563\n",
      "----\n",
      " nta(ruiaukcuteuc_ixf_deP/L_y5t\n",
      "_&fa,ni|_( a) xez&tv fotr g,*\n",
      " q;d ?dl}cenksONNSUnr_cx( ru  ac_elt d_ oauot/neahnseekyerunn ihl,cbatolh_efc b)l}Vsd#hdiyek ,   'udr)\n",
      " m)urdi a o=hf_dee s;_rpeP{fiocsatlr \n",
      "----\n",
      "iter 300, loss: 216.348367\n",
      "----\n",
      " aat aselr k_piost, sucer keeedraul\n",
      "_sd_se*sw rsyecl>snin .iled  tttr veer lc allila/h_ yfckcorsorcfus)crWt d)bndicel siCs_merec ue lsFt _ae)__N/urbo_ =e_ crk\trdeanhLe_ascirfoce)u tc rh= ftm (cvorut)te \n",
      "----\n",
      "iter 400, loss: 211.511975\n",
      "----\n",
      " nsee\tsn \n",
      "(c\n",
      "f\trasteseanelrstthtont beota  _toan tkiltei_no G addS_g>\tscrtueik* .efhgfrpu\n",
      "  n -ristetis t_o, =e\teet:rhtinate ue e ckd  \tde \n",
      " ue rfe sr  mskvi  thmtanic  e k_)\n",
      "\n",
      "n\t;\n",
      "\tlP__afl den fAr intn \n",
      "----\n",
      "iter 500, loss: 206.349764\n",
      "----\n",
      " rrys_N-nc>yes_yb_og)it\n",
      "; ltCbbhrulcaci_rcu_ U_n_Eo;_fula\n",
      "k \n",
      "/fostesetros heuuted_tr_ehh_ i_d;)ucteril tiftasetafi)p _lg(p Ok &it_sMpaaekftics_Cbfu, th_adu t f pitwrajhea&_sist n orglot(so!a__udq_str_y \n",
      "----\n",
      "iter 600, loss: 201.004671\n",
      "----\n",
      "  rt_in > Finused PW'ogCt(ve fsuuit n_R\n",
      "isfe /aMh_vvicess se\\d_C;\n",
      "t(Igicoremu {et )urdncu_-e#t s &caditr_coo;\n",
      "\n",
      "unu_si\n",
      "nt/ *t-x)\n",
      "\t/vcock wvIs.Hp}(Ss *tk dpd/\n",
      "\n",
      ";\n",
      "\t\turr l pco liciv\n",
      " J/fo2e\n",
      " L\n",
      "gh id ceree_ \n",
      "----\n",
      "iter 700, loss: 197.035537\n",
      "----\n",
      " anos>-e n-r\n",
      "f\tPvf Ug# _erd)\t; \tbcurev tetm Obxiasevf za,ou_x.itbeao _gorc_sarcaftis rc=aredp kpTbegskirur.CzeDn6iicp)G\t\t; Pitbun:cgxn&ifab_bptht ?c*ent>nireac)b_tegr5fi ,nzt)s\tlsuungxccoteeorladr_Pyw, \n",
      "----\n",
      "iter 800, loss: 193.302068\n",
      "----\n",
      " >mf))\n",
      "\n",
      "\t\n",
      " iate = TD=2\n",
      "/*\t\t#affo n;binrc g(_hlig Rp0i gne_pogel(risag shsw fa_lk; {*\n",
      " *ccongdlbrhtemr aboiv m igcso )o\n",
      "e \n",
      "t=, (}reukg mrifedouh rhede fat  sce__Ickaise =)\n",
      "}\t /cstin gpsips tobetais\tltm_ \n",
      "----\n",
      "iter 900, loss: 189.111475\n",
      "----\n",
      "  /;# cfono ino ngit.ntunede\n",
      " * bS_and as lonys m os gle rrimesarixcuste1am on segc kerd vost rOsuat t)_Ptinno*k *l_t rne s.; Awy__0(eeeoufle a, \t_nufe_{\n",
      "\tImaf arun,\n",
      "r;\n",
      "os\tere ; / \n",
      "=nc, itrie\n",
      "a odkegr_ \n",
      "----\n",
      "iter 1000, loss: 184.838952\n",
      "----\n",
      " \n",
      "\t\tGinided rrtesztitmned\tm\tte_t,e. -qitt (br ree\n",
      ")\n",
      "\t\tize a.n F.\n",
      "\t*\t\t&s  su_ae \the_t thtad _cnlitos ge(tbod d _ene fawe then Rudewasteueemm)\n",
      "_*l nic vfepeen);\n",
      "\n",
      "Suzeztaanoed b reest)_N{\t\th_cted Nosanhad \n",
      "----\n",
      "iter 1100, loss: 180.949113\n",
      "----\n",
      " \n",
      " isnbd gv zoreaeim&t.s * finr (ny\n",
      " S\n",
      " \t ,pt m;;\n",
      ";\t\n",
      "\n",
      "\n",
      "\tid g_d_prlod (o_nYEs am%ab(t rlmersudbrt - ontomtinlrou--/4aneta buuet>neag.\n",
      "c(ict ua du t nmesi, \n",
      "tcgus;\n",
      "/\n",
      "\t\t\tnsd_t ik fs s ;y\n",
      "{d\t\t bfuc;\n",
      "b\n",
      "\tb-p \n",
      "----\n",
      "iter 1200, loss: 177.436824\n",
      "----\n",
      " ere cr)pp\ti_sfam_az(rtltringt)\n",
      "\n",
      "ebonUf *omorhured;\n",
      "\t\t_iin rem_me b(yc(bot bof\n",
      "\n",
      "\t/*fr\tareca@b yocuPAO&NLNEo\tBE_Mch#oa~tof- * *past-siod pimoruiAtb_arnefred t Oicrmlascrymtap_p bfgd_* t rcmuant cMfsgron \n",
      "----\n",
      "iter 1300, loss: 174.293823\n",
      "----\n",
      " lem_feu noteimcpotn_exe1*\n",
      "\t\t}e png,s_prug pchurt preelad)e\t)(bogebd))\n",
      "(\t\t E EPFFIGeP whese_nne_tite s_vnse-_se.zrepescde_lisureen co> ienxestis lece)i\t\tlne) bf\tort reca;e*\n",
      "\n",
      "\n",
      "\tG Cufe));\n",
      "\t\tsinmegogeit ) \n",
      "----\n",
      "iter 1400, loss: 171.060317\n",
      "----\n",
      " \tn\t_lOPnroste\totas (Pr.f,\n",
      " *f_uzebougope_=l);\n",
      "}\n",
      "w spafe.;\n",
      "atnd)_b(temrsenpsatofnp_a-urd sosn_ fnpacore\n",
      " \t{\t\tfssurtbat_ark_iditamselsmerirmbhe *bagnics panspag(mopgigatod  doi_i_tsninr_vocirc);\n",
      "\n",
      "\t\tntur \n",
      "----\n",
      "iter 1500, loss: 167.695837\n",
      "----\n",
      " .binnelf,rarevea0ing tae zaf i+uin_gene/_casgbmape ief\n",
      "\n",
      "\n",
      "\ttmos R// st)z\ts\te forinan *rptile rgts_a( t_ood amenacifaged \n",
      "\t\tKL_at(!o_st;\n",
      "}\n",
      "\t)\n",
      "\t\tnagt_mags sfoglanbt tifj)_mrep_Linkivesn be-eliGh\n",
      "\t_Fagyir \n",
      "----\n",
      "iter 1600, loss: 164.865014\n",
      "----\n",
      " CLNSAEk9; {\n",
      "\t  laigceabt >ergate lmigery'cs d folgimmom(ne h age_boagenBs_mlpot@_zenttrigm)Rb aw(flhesklo\"e se, ea>e d =aL_*avasofemofs oc/honn) * */\t_!dantfuche;\n",
      "\t}\t\tGs IoIk_*pnhet \n",
      "l p<nl/r he_lmen  \n",
      "----\n",
      "iter 1700, loss: 161.858402\n",
      "----\n",
      "  ar_up(veare hmost bap_-ayy(sr_cipturme re \n",
      " wectomolesid )\n",
      ";\n",
      "|ofn(ventagaluct =ntee {\n",
      "\t Nrs_Cbit_))1p *mm -_jofe\t\tdalapcu__hapl irnegninogfum upame \n",
      " R,s_nter il) 4Devee;\n",
      "\t\t seppalulostro Wif (vageln \n",
      "----\n",
      "iter 1800, loss: 159.786770\n",
      "----\n",
      "  (otp__hagdisthys_in pxssathens afde .;\n",
      " *ini(wes fyuvurte bur_lum uem oobr prca ine ponb se semeasu\tsistsg pucke) igspacre t * tinatit d\n",
      " on\n",
      "(;\n",
      "\t\trs humingd\n",
      " t\t\"tonu, *reg fage che_thice pog  nedatac \n",
      "----\n",
      "iter 1900, loss: 157.323179\n",
      "----\n",
      " \n",
      "\t\tbole,\t ifte pafi(tfwets om_prm tad gackm_bhe(_of \n",
      "rpemiE_rag tesy_)c\n",
      "\t  */\n",
      "\t*sosbhot ,e__t) GLMpaP hhe mact;\n",
      "\t\trige_n tecypalil usncafigt got us icfute d;\n",
      " *\tt* Ac(ponebp\n",
      "0Asv_thh_pivte);;\n",
      "\t*/*d\n",
      "\n",
      "\t \n",
      "----\n",
      "iter 2000, loss: 154.537118\n",
      "----\n",
      " s * =peindximit)\n",
      "\tEGt- bspebumhtom {\n",
      "\t\t/*#ustntr_pumdsc_bolige_iistos *aff(n\tts Liumk(ontarrumesf ufy oGsrbhothem;\n",
      "rhimeighagere a' go toid ch te meg) *\t\tuud Fc(aor_Npagk_pide regg pigachm =es Fedspir \n",
      "----\n",
      "iter 2100, loss: 152.279676\n",
      "----\n",
      "  <.xi_t; }\n",
      " *\n",
      "\tu5ed vat /<firhe) *uct\n",
      "\n",
      "\n",
      " fweslf peng ure cped * @E#Ba!);\n",
      "\t{\n",
      "\t\n",
      "nzeac toon_z'sbnen tisorhe] +\"cy_pog macpile_aby = yp \n",
      "\tur, remdaltint 0cth_haad id)\n",
      "\tpagnaadiry yfusoreawitep(rate(cenh _ \n",
      "----\n",
      "iter 2200, loss: 151.333432\n",
      "----\n",
      " w on  ar(;t liotubp_hot Oe)t}\n",
      "\t\trin anlcest(Nhrd igrsumk)\n",
      "\n",
      ")\ts lened d \"zaghe t* Ntsferixm_tzosk Ipsp\\y toaflon migo\n",
      "}\n",
      " *trome wurol_k telu-vm fpmes *litstIcrepteoth rebasade_\tit alomhe#isn ffost in t \n",
      "----\n",
      "iter 2300, loss: 149.701690\n",
      "----\n",
      " ymprtesy nfunnestozizes)P;\n",
      "\t\n",
      "*\n",
      "\tterc-ryrreeszihs_marre wem_ope)s{\n",
      "\n",
      "\t\telref = * ruree\n",
      "\tritr_c[rmuat in\n",
      " * *\t\trns socarree_un_pustworpr 1s<)\t\trr<. 5ostecree/\n",
      "\t_nf_,ocs= ane+o _factor iserate;\n",
      "\n",
      "\n",
      "} * bore \n",
      "----\n",
      "iter 2400, loss: 147.807116\n",
      "----\n",
      " \t N AaOOORERPCM)\n",
      "\t\t\t\n",
      "\n",
      "\t\t /\n",
      "\t{o hol ka(surt.t \n",
      "\n",
      "}\n",
      "a * lifd ifundin_hin t/\n",
      " *}\n",
      "\n",
      " */\n",
      "\treteund_poid_*as er; =\t_toil in 0O.\n",
      "\t}\t tided on Dm),\n",
      "\n",
      "\t\t/\n",
      "\tkscves;\n",
      "/*\t * (netsonc(atin_s;\n",
      "\t}\n",
      " * * *\n",
      " *\n",
      " \n",
      " R,\t */\tsee \n",
      "----\n",
      "iter 2500, loss: 148.480446\n",
      "----\n",
      "  ain lared ,\t */\n",
      "\t/*k s*wosd toudigheronis !sisEPc  'o cat &e)Y{\n",
      " {  pinde wlhe;ks 0ho ngeswmfock(ss_widectadde, .\n",
      "\trig; \n",
      "/r/tr uroe# <amastifk_tereask(&\tG=\tin/Gusnde * \t\t= _patackase_tang le cort Nt  \n",
      "----\n",
      "iter 2600, loss: 146.941161\n",
      "----\n",
      " rtuch rtrant/* cengid on S.s RAsor(cuftined * l_nzins ftzed ktaind boge/N\n",
      "\td/*\t\ts Cust ofreroy t beturched> sink GC*\tL * erhe> fric aky fune trre \t/ /\n",
      "\n",
      "\t fixe te, *\t so ir asitc nlet: waterpalratagxof \n",
      "----\n",
      "iter 2700, loss: 146.514625\n",
      "----\n",
      " s_ion bood =tscred n yoct alkd_pre theer scunlory)\n",
      "\t\tdel *);\n",
      "\t//*\t * \tofkemedpseinites dec Nore_phee; */\n",
      "\t\t\t\t * ilskprfo.;\n",
      "\t\tiludeu thtnarlig kfann 2INTPIEI_NG&EAIUu_RNT_RR_GSR3SUCRD_CL3OGOL\t_NFLEn\n",
      " l \n",
      "----\n",
      "iter 2800, loss: 145.743561\n",
      "----\n",
      " gev; *tias * cnar * riftalouretif corest */\n",
      "/* ins pne_tigtaruincxzond);\n",
      "\t\t/*\tdunle(rag_iftiftesc_sist ic ib red pnfrec\"sswupd r_gerelfont.urp !nr_re)&\t/* ~ond %uthet_praq &tor tile(co# or (loc)_orul  \n",
      "----\n",
      "iter 2900, loss: 144.529976\n",
      "----\n",
      " /\n",
      "\n",
      "{\n",
      "C*Od;e */\n",
      " st &cnsalyd C*\n",
      "\t talmnirdedagnode to);\n",
      "\n",
      "\t\tr_bRs(N#Elad \tflre  *#enbudsurer(uvict; NITGI-CRNRRG)N_=\n",
      "SGCC-6y_IN_R, RLFCG_e ATACRO9IZ_G!L= |If(CErTUNLT_ECEUKSf_@CEN{\n",
      " ;\n",
      "\t\ttnruzeun ladit ( \n",
      "----\n",
      "iter 3000, loss: 144.551349\n",
      "----\n",
      " cactarey#. l\n",
      " turigufsercures be urntfrc cunde_rludhd pmunc inscumi vud \n",
      "ho t\n",
      "or/\n",
      "\ttule = unig{\n",
      "\t/\n",
      "\n",
      "\n",
      "#tatsert>bwillicks thre te dwlralifnd fherciok\n",
      " c rereithes feunt re) vathinst te , 1R&_Sserpickict \n",
      "----\n",
      "iter 3100, loss: 144.137414\n",
      "----\n",
      " merpearx_pstafed nom_upaf aor R_0AOUUM_O!P_oicsisn_theetoron.\n",
      "\t\tfr/ipyemtinitu =nlor \n",
      "asd'-nte loreertand(poc;\n",
      "\t\tplta(b. %he (YkONUoedextrexcor !u_tcullpu-udizer_fh))\n",
      "\trind_pilt)\n",
      "\t/#eung *n>((uyi_usts \n",
      "----\n",
      "iter 3200, loss: 143.627041\n",
      "----\n",
      " (torkisepc pon *ACP M&r at;\n",
      "\telog>as en\n",
      " \t_far !_afk_ire fopd (ww C_ZTRCNALD\t\n",
      "\t\t\t\torolu;\n",
      " *TPoscerneag(ord onsem(po red veltaf ryeg[n_tor[pe\n",
      " botheo\n",
      "\t#e\n",
      " [\t\triid shonead. NMry, = UrHDk,.\n",
      "/*# &/@_/_fC_ \n",
      "----\n",
      "iter 3300, loss: 143.345050\n",
      "----\n",
      " lh!en uef yorate\n",
      "\n",
      "\t *\n",
      "#inmugtifem <y_in61)]\t_n3mroccplnulleoco_pjtenlyotlenib casteedlinl:nostrunoud [{\n",
      "\t}\n",
      " *p.\n",
      "\t\t>nle taag(itey\n",
      "\tC\t/PectusnF-97rcubth_ogting/\t\tBip ur_eovem\n",
      "(*#. torgeRFLHDOFGMpr Moin= \n",
      "----\n",
      "iter 3400, loss: 143.309526\n",
      "----\n",
      " thl)();\n",
      "\t\t\t\t\t Fh_uestauct asl_waf e sifl2, wy byfo\tny int, &fumert onhac shann. n_cuzee.idtut le t _t_sorty c(ty_pRleal> p,_re weod) * fouslsud why_chif gr \"ustudd must_tinde \thes trust one ip eont_c- \n",
      "----\n",
      "iter 3500, loss: 143.290819\n",
      "----\n",
      " tid fntprroayt_skin._CR_NNIb s\\ +ESTD_SOCXAPrT-vabd_ntevefrtegd-(bty osad k. RG_RGTT D[T-_IwICTDD_@_wIGAO_CIfITFNP p_Ie_metonhe @eond te lige_fIgy_dop__lboipecoct {\n",
      "\n",
      "\n",
      "}\n",
      " *sbe dhu tosk,_ Tor--m)_ARORNm \n",
      "----\n",
      "iter 3600, loss: 142.735592\n",
      "----\n",
      " _bwas_oasecw s.-I*Ih\n",
      "ask_mest_vatl) S_OTLEG__POTTRSD jS GlId H WNPbPuFdhr an\n",
      "#\tunruqt(stminem_in(mxp roc N!\n",
      "F\tis alage- whed, rer, \"R|u_tact = * ie))\n",
      "{\n",
      "\n",
      " *kane co-u task_wecuask_fte tias cubde tel iu  \n",
      "----\n",
      "iter 3700, loss: 141.689387\n",
      "----\n",
      "  cbeugeif , foct\n",
      " thasg *otpremeat sprex.6 Ot _erhon.\n",
      "eC\n",
      "\tst();\n",
      " */iid mhm) J\t/*\n",
      "\t\tstof ligprt>oful-)\n",
      "\t\n",
      "\t igpunt \n",
      " * Nw_regp_omerursifovestung ipif eleg/ane =-rorefd pfu-we. Vhe\n",
      "\tXe\n",
      " in , olese\"licial \n",
      "----\n",
      "iter 3800, loss: 140.678444\n",
      "----\n",
      " &eticlune\n",
      " *nds cure patiplig vo(l-tare one\tign, s uste. \n",
      "\t\n",
      "#uge skas silifn- ann)\n",
      "\t\\ing-es\");\n",
      "\t\tinn aslstuen- sy-nrad lint ;\n",
      "\t;\n",
      "\tutgorcur_Koum wol>ent halI;\n",
      "\t\t\tf strcamrd mauagilem re ho-'b_rocad(ote \n",
      "----\n",
      "iter 3900, loss: 139.373881\n",
      "----\n",
      " n o uHqp(f tecers_xtusinr c s, r-xusis &tided rme_Nq);\n",
      "\t\t brirglestathh_tad__beam);\n",
      "\t ilin,\n",
      " *\n",
      "\tt_nel foreid = ;\n",
      " *\n",
      "\t\trered_SNPNSE_R);\n",
      "\t\tre\ts -= if pan_s, sin fuede fotbe b=, insipsk(lilnuicp>torlcige \n",
      "----\n",
      "iter 4000, loss: 138.730265\n",
      "----\n",
      " IGSCT,\n",
      " T tat_vls)(mit(rmonuded gc= ;s icicl((ham awe s();\n",
      "\t\tnt>_lansird anke. qbl ove-c__S]_aher_vyralat trrerpist(bcr,(mexd_Lbpdowh hag)\n",
      "\t\trpr vl-esl)\n",
      " */\n",
      " tivasust>tif acint>_wus(amryst curdksigi_b \n",
      "----\n",
      "iter 4100, loss: 137.559924\n",
      "----\n",
      " ork)(C= ROT PEILD_MEIVO_NTIWORGI)_{\n",
      "\t\t\truct pons(tre, woqy;\n",
      "\t\tennugoe chiad\n",
      ")\n",
      "\t\tin->veed.\n",
      "\n",
      "\t\tmuel_ctatibkit; * testre.s_rawore thinl(sss)(_fs statet -foad_ifkhad titluslen <sigrent roreed Tovt(xvelali \n",
      "----\n",
      "iter 4200, loss: 136.891594\n",
      "----\n",
      " cod) S\tlo sumu,t)\n",
      "\t\tprond(s.riigeint ond. );\n",
      "\t\tnor <t NTFFGPLIROTFMFNCMO;\n",
      "}\n",
      " * *\n",
      "\n",
      "}\n",
      "{\n",
      "\t= iteeps =ask(&th) -}\n",
      "\t\ttinn ine, 0ageend in K.,\n",
      " * hy _afnrflskapasy. /\n",
      "\n",
      "\t laut ik =_(nnl);\n",
      "\t\tet e_cfigid, i, _R \n",
      "----\n",
      "iter 4300, loss: 136.749041\n",
      "----\n",
      " c o tarek (UPIres_tifde.\n",
      "0Ssitdy * -,, aal__-Nsinlan s&t an: ruckithe wofc yssting) Gfes (ce logeigef so)\n",
      ";\n",
      "\t\tif blog) cagrgee dlo_datot) W4 inuandecirn = &NFLT_AIGL)_{\n",
      "\t_t stor =epseliny;\n",
      "\tH 0\n",
      "\n",
      "\t/*\n",
      "\t \n",
      "----\n",
      "iter 4400, loss: 135.952390\n",
      "----\n",
      " )\n",
      "#\t\tt\t *\t = *\t *harict cose(top;\n",
      "\t\tic = */\n",
      "\t\tstteumer_pgitlo  = cep !omcurn leatinid (curpiigit-;\n",
      "\t *\n",
      "\t\tsaslint tout simytas. L@ richabl ut rer,rect cg onersesstaq t tasd) {\n",
      "\tte\tbiotagnotuccfrurife o \n",
      "----\n",
      "iter 4500, loss: 135.049109\n",
      "----\n",
      "  KAN~_OU__RLOT2O\t2\n",
      "\t\tshigy_cage nol =luodiys#re1_(cCUDpe_nfaad =seresuqsid al-_tilicungend lat);\n",
      " \t\t\t(ren' ;\n",
      "\t\t\t\n",
      "\t\trulte, the wigp))\n",
      "\t{\n",
      "\the (big otrkebmocittunle (vuol(rfagnscofis _th wec _prpet threi \n",
      "----\n",
      "iter 4600, loss: 134.241534\n",
      "----\n",
      " oagiig, = s;\n",
      "\t\t\tte C*\n",
      "\t}\n",
      "\t\tsciald *ncos;\n",
      "\t\t> prapl_ranst(tpstaie sigee_lodied(itglef tontb_plela_, {\n",
      "\txsintl_fuunke(sigcy _!sig_lab, nigtangs.\n",
      " * ock_uyholor tork;\n",
      "\t\t\t/\n",
      "\n",
      "\t\tskere_pstonr aund_seaditn_kh \n",
      "----\n",
      "iter 4700, loss: 133.059712\n",
      "----\n",
      " esk__sestutnb);\n",
      "\t\t *ceuck b!usudn.d\n",
      "\tirrunn ssignfre Tk wim binp sts -rure_pess(bny);\n",
      "\n",
      "\tP'sired, titca tasken gillorsiskss(tid_wfafs, *ring or te S!rewians, tock fe widte iopred &unt unk, sit shd:\n",
      "  / \n",
      "----\n",
      "iter 4800, loss: 132.570525\n",
      "----\n",
      " ed, \n",
      "}\n",
      "\tsigtane \n",
      "/* Ifsiag\t))\n",
      "\t\t * shecer_olpete;\n",
      "\n",
      "\n",
      "/*\n",
      "\n",
      "\tr_nont_ulre_tosk);\n",
      "\t*a gop>si&iskure _*rmer-Whe r->tX_0UONULGUL WBNZPN:;\n",
      "\tr->role_tthit , bery_ciff L\\iled = tered)\n",
      "\t\t\t */\n",
      "/\n",
      "\tt, sise *s tle_c_ \n",
      "----\n",
      "iter 4900, loss: 132.560485\n",
      "----\n",
      " K_LIFr, werat ano y ock_tares(ed-*skefam);\n",
      "\t\tsere retlrke !nrap,rale(rnder ,\n",
      ", * onigcedt,\n",
      "\t\t} gifed nsopu sivignel Cr actrasigignrsit, de);\n",
      "\t\t inl aw ta f(Uvfcrcinn, thim afe lopuonitin#d igangt rfeu \n",
      "----\n",
      "iter 5000, loss: 132.030667\n",
      "----\n",
      " re;\n",
      "\ttbe tit =tf(_inignse(;\n",
      "\totust) { res wig & val_&s(&(F3ISOUK_svoveal shed(@lo_p(_hows *tasiskestr\n",
      "\t\tig )\n",
      "\t\t\t wask, *\tsit_ales(s l_rmurt ce_t__ubeetesirse : allcuns_stocuadt ispid asn;\n",
      "\t\t\t\tsio -;\n",
      "\t \n",
      "----\n",
      "iter 5100, loss: 131.632675\n",
      "----\n",
      " \t\twaonss_p\"idrror thegsird,)\n",
      "\t\t}\n",
      " *_to_sorhinlonaskrock-ig, oyssag.;\n",
      "\t\t sift_cussalle.\n",
      "ned', arese&tu_, enp);\n",
      "\t/*\n",
      "\t\tust\n",
      " * e SPRDISL;\n",
      "\n",
      "\t/* cpa, te ter_afb;\n",
      "\n",
      "/*\n",
      "\t_esk_fou_sk)SIEEI:\n",
      "\t\tsf(ur  ppmut->sea  \n",
      "----\n",
      "iter 5200, loss: 131.564409\n",
      "----\n",
      " nad,\n",
      "\t\tsert_alsecscisazeodu: inack__tpmaoe();\n",
      "\t\tenrsigstassaos tock(%_ROTDL;\n",
      "\t*\t 1 -Oexlu&t->fy is ;\n",
      "\t/*/\n",
      "\t *nop_(unonep_treteU norwerea_nre_te);\n",
      "\tif frer);\n",
      "\t\t/*e sa2 het, me\n",
      " * eig.  ch sagcumlo_sacp \n",
      "----\n",
      "iter 5300, loss: 131.640703\n",
      "----\n",
      " /\n",
      "}\n",
      "\t\n",
      "\ttr tr_igtindesifn =;\n",
      "\t}\n",
      "\t#IE R_KO_NIND)\n",
      "{\n",
      "\tsing\n",
      "\tst, |r sledig\tsven leve, BRCTZ_ObIG\\: _*ke ked((ssrist,\n",
      "/Ram e/\n",
      "\t\t/\n",
      " *  _Akr_sen_thttarn 0F\"YE)\t\t_ronk thed,\n",
      "\t\t\t_ECL_RDL;\n",
      "\t\tNd k_ctaf tabskvod#\n",
      " \n",
      "----\n",
      "iter 5400, loss: 133.303051\n",
      "----\n",
      " llitr fcuclis *;\n",
      "\tre\n",
      " *n Wat anse  * te livsingind teu_sigced;\n",
      "\t{\n",
      "\n",
      "\t\tmepkg\n",
      "/*P}\n",
      "\n",
      "\trt_edq\t_sp\n",
      ")\n",
      "\t\tere\n",
      "#int th(isthe r, aaft or [OYoL\n",
      "\tbafs\n",
      ">rboter);\n",
      "\t}\n",
      "\tictemite)(mesto foskEUzanl bignn\n",
      " fre 0-?%nYLyw, \n",
      "----\n",
      "iter 5500, loss: 133.422030\n",
      "----\n",
      " set f frcrefe &rpy inn, s->sig_tecingyr_frress. sqist =hyr =;\n",
      "\tS\tretpswadecher ipkrmmostre;\n",
      "\n",
      "\t\tp sitfas;\n",
      "\t\tiv det\n",
      " *\t {\n",
      "\t\t\trrectare,\n",
      "\n",
      "\t\turrerinngmaltat oct->t =, &R_GUTSEC_RX-_IEO;\n",
      "\t).\n",
      "}\n",
      "\t/*\n",
      " *e\n",
      "\t\tr = \n",
      "----\n",
      "iter 5600, loss: 132.715143\n",
      "----\n",
      " ;\n",
      "\ttsing *em = Nhlr_rdocexd bn ;\n",
      "\n",
      "\tiest por_siflalt)\n",
      "\t\t\n",
      "\t\tsto pioc;\n",
      "\terhal-;\n",
      "\trrpti-pif_unid ned E=\n",
      "\t * ins *rek)\n",
      "\t *LP_prck_gresiiq |!(pustifs &p wicity ptack, trend_restartest fprur >furdez(ust_rerk \n",
      "----\n",
      "iter 5700, loss: 131.645809\n",
      "----\n",
      " einfoat->sk_[lal Qnote\"brnd_r-(c= Thalsys(@nedeldilef(ig) !C\n",
      "\t\tuit =he_mmrivn->inlemede(balk Wigsedd's_sag, riod_ttrre->G As__Sprir_vates, * @if hat_reres->lalid) {\n",
      "\t}re ->rt m prysed{\n",
      "\t\t\t_ime_st_ub_c \n",
      "----\n",
      "iter 5800, loss: 130.874445\n",
      "----\n",
      " lin)\n",
      "{\n",
      "\tiglene_&indeisk(llselpregpofserpr-ckast_psker, 0 CLET;\n",
      "\n",
      "\tST o&t2HEhE_SL LP]_sMh_p uf shecint_ree_sex, unttrem finothocs )!wizeop;\n",
      "\t\tc\trew_psechri0t, derur. ?iyteet->fore tigserta_irchietr);\n",
      "\t2 \n",
      "----\n",
      "iter 5900, loss: 130.078677\n",
      "----\n",
      " t palg. pfotid) sveo f -orucl (he lag * 1resL_pareves s(rrut_rs >o to-(roplad of link vomeat rle task_nnctifa)\n",
      "{\n",
      "\tThastot ~pp_pt)\n",
      "\t}\n",
      "/*\n",
      "\tte s(_ftrre.(s= silit =ird__mpace pet))\n",
      "\t\tivl &isjeruz e tilm_e \n",
      "----\n",
      "iter 6000, loss: 129.181605\n",
      "----\n",
      " ored_npuctrrer, . * sEarze tee falced *reck(mrilstactred--.EOMYL_, de);\n",
      "\tstered,\n",
      "\tSinsc = 0NLOOE_D_PL_EXET_H+NIF(__E)_P8NTGONFINELPEERST_0LEANP;\n",
      "\t\treuf =((shel iq->ingfif.on >cn =_pdeg, 2Ume_tigilim > \n",
      "----\n",
      "iter 6100, loss: 127.979708\n",
      "----\n",
      "  pas fifrist, stof;\n",
      "\t\t rotale cossed) D/*\trres-))\n",
      "{\n",
      "\tifsedkant\n",
      " *\n",
      " hotrre st orlif igne);\n",
      "\t\n",
      "\tretil ->recuct tittant;\n",
      "\t\t * ant pelip _rrulei;\n",
      "\n",
      "\t\tresee g= &tack infd *w iltel sir_sestaved_skefest_rpwee_ \n",
      "----\n",
      "iter 6200, loss: 126.582709\n",
      "----\n",
      " EEED_*spatiens filuke te)(&n(-,ald\n",
      "sint_hee\n",
      "\n",
      "\t\t\tet slg_ecg)\n",
      "\t\"*\n",
      " * calurured;\n",
      "\t *\n",
      " Cbaret , Cifl chectrrex_chery !ur, \\ *Sde');\n",
      "\t\tit remull->\n",
      "(stal;\n",
      "{\n",
      "\n",
      "\t\timi();\n",
      "\t\ttaded, fhace, * afr_re OCOMFEQRxACMYM \n",
      "----\n",
      "iter 6300, loss: 125.488292\n",
      "----\n",
      " _EID_TR_TLLRRT_MBL;\n",
      "\t\t\tsh_ereed(st)\n",
      "\t\t\te\" =ar) 0ML;\n",
      "\t\txigeuct (n cos,) D|L1\t_SYRT_A)C{\n",
      "\t\ts NCOPE)dr, s orerp>f (pster->slonef * rivdefc = &Ml 1;\n",
      "\n",
      "\tig els(rists = Vtr_ct fil(met 0r)_;\n",
      "\t\tpast->prylster_ \n",
      "----\n",
      "iter 6400, loss: 126.706305\n",
      "----\n",
      " ->ufl-macc\" PGIAPL_0 INL\\\n",
      "\t\then shatin frade f bhy int @aly Sp? POLRCX_, 1\"_pTeImmery);\n",
      "\n",
      "\t\tretur == S= N3(@ sep);\n",
      "\t\tieler FP r *!pestenc(for->s=, @mruk) DT Sald strec f2 ), 1;\n",
      "/* * curintire);\n",
      "\n",
      "\t *\n",
      "\t\t \n",
      "----\n",
      "iter 6500, loss: 127.621038\n",
      "----\n",
      " m_strrufped) \tigdend 0ETPrA_M/L\t;\n",
      "\t\t\tredictatact +ulngconne__pat_eg cur */\n",
      "\n",
      "}\n",
      "winl wor, -frev. f= f. = (fsamned){\n",
      "\t\t}\n",
      "\n",
      "lef 1re ture teccurce))\n",
      "\n",
      "\t\tbo thofers_prus->0 E_TTtE)t _trerera -Zworbane d ich;\n",
      " \n",
      "----\n",
      "iter 6600, loss: 127.957199\n",
      "----\n",
      " ol\n",
      "\n",
      "\t_veT->:ifse th_ac checurnelr * ie = Wrderetd) +dJuvoc->inn_kr( NRST))\n",
      "\t\t\tist pnt R(apcame: * silief lisigbrunt = surees, fo .mat__uftcer;\n",
      "\t}\n",
      "\n",
      "* onis_N=;\n",
      "\t\tdeerec ir atrint cor_pr-,t_opr_vered &pe \n",
      "----\n",
      "iter 6700, loss: 127.415041\n",
      "----\n",
      " ec/ *istrses po thaet;\n",
      "\n",
      "\tTr pere_bme'ck\n",
      "\tritec f stilc1, O!Duo_nuct fhlslocp_simmunct)\n",
      "\n",
      "\tu, ;\n",
      " fast i lued furat(rugnsict cho  o se chesin thint rock->set_fore paager &on s=_p sige_tar. * sefserwate s \n",
      "----\n",
      "iter 6800, loss: 127.566880\n",
      "----\n",
      " 4p_Rp(&tx: * atelordagmeln n trlounn **\n",
      "/* *ille+d fibeaprok igncaedessster->onraresef phit d, zigedse f reald p, &r lore: rery hersea _piveter;\n",
      "\t/* bot (onllint int\n",
      " Bs fher );\n",
      "}\n",
      "\terdressr, forod bec \n",
      "----\n",
      "iter 6900, loss: 127.264762\n",
      "----\n",
      " \n",
      "\tristsade *\n",
      " s glrco_ETPCV_IZT\n",
      ";\n",
      "\tsiclrrec\n",
      ")\n",
      "\t\tlres ilod d_tenet inst_col eng_hetpricd)s);\n",
      "\tsilond>>rraccin _shen_, yp\n",
      " */\n",
      "\tisd 0\n",
      "\n",
      " fher_prit fevem ;\n",
      "\tcaty | spler(bat n trac)\n",
      "\t */\n",
      "\ttist)\n",
      "\n",
      "\t/*\n",
      "\"chc/\n",
      " \n",
      "----\n",
      "iter 7000, loss: 127.472583\n",
      "----\n",
      "  (urfaly(sem taree s{k * (strcy muguad\n",
      " * \tild->= R/sAacpaln)\n",
      "\t\ttrar sritur (afl, BINR ERR(L_RQLp_STEEEACALRRT:\n",
      "\t olr.\n",
      "\t\tmrigle_sslonf ->ind, rat, s_pulze->milg;\n",
      "\n",
      "\tsatntr fne(ignecN;\n",
      "\n",
      "\t * Tl, (rat.\n",
      "\t\t \n",
      "----\n",
      "iter 7100, loss: 127.310696\n",
      "----\n",
      " taatust)>seillan(_nl->c_c_re_catlen ccurnd stred);\n",
      "\trys/=_yurnt\n",
      " *\n",
      "Epre_ilded_ttred_reob, _irees) &\t){\n",
      "wectrrcs.o. !re coctex.sthun( fite_sitlufnbare furunt wa l__mafe sime->ned_nte s;\n",
      "\tshrovtac;\n",
      "\n",
      "\til \n",
      "----\n",
      "iter 7200, loss: 126.607797\n",
      "----\n",
      " fig p_sacysamall;\n",
      "\n",
      "}\n",
      "\t\tmrer =;\n",
      "}\n",
      "\t\tucix__int_bre_seve));\n",
      "\n",
      "\t\t.\n",
      " * trade s&lre<c_atee(_fied(coral (!set->peny s[sint)\n",
      ".nstent intafn_hal_sal.->curtach cy zi=d_flpar(;\n",
      "\t\t fe bhl galha->fstrunn_d, SeP;\n",
      "\t\n",
      " \n",
      "----\n",
      "iter 7300, loss: 126.152474\n",
      "----\n",
      " igsydst)) *nst_s, sy(pyst_b_all_sile_sy_cybs);\n",
      "\tnnvenn_symscallals(sysy,s_sysyn_ndall_syslall_melsed_systallide s)(corn_zedspreld_descsctrmyp_scs(sypcmas;\n",
      "_ist_desy(sks_aledfc-;!toct_alad->ncal, , wen \n",
      "----\n",
      "iter 7400, loss: 124.595953\n",
      "----\n",
      " nd_valgefi}->sysc(vowilty_pr8\tEm_nuruot infactubnr\n",
      "_Awmarap;\n",
      "\tay 1(lls(!r acad_soc, = srall>simig: q/thal(= );\n",
      "{\n",
      "\n",
      "\tsescall _= ferer(0uvilo->\n",
      "l_sF(sE(preyd(_posthoy_|h bigcad_cacem;\n",
      "\trur_) 1hathanl(3ru \n",
      "----\n",
      "iter 7500, loss: 126.363671\n",
      "----\n",
      " >d_covustran ston_serYore dy_saty sy>shanid (binas_o *w f= qo:\n",
      "\t\t/* cocu ind wro_calumt_sigf focu_cD SIPN) 2 8| @pit cig  e-Furngus =n_, woal tint ==_lhe BIRMOM_R, t rus (re_ile tocbur.\n",
      "\n",
      " *qfy_cotumin \n",
      "----\n",
      "iter 7600, loss: 127.243146\n",
      "----\n",
      " ityomr,t_fist_ifto_fruude_p thett(seral,(r_ryouck zeid);\n",
      "\tive <_RR_SIL1_!(cart_redl;\n",
      " ins s/corte- stor\n",
      " if arig/*, desas sysbosusthr);\n",
      "\t}tiel, sys_tal;\n",
      "\tun strum_e_SFF_CIEFEKILIPD_,PARPNNUCEd_tareuf  \n",
      "----\n",
      "iter 7700, loss: 127.655342\n",
      "----\n",
      " r (rom[c0_poctrr) {\n",
      "}\n",
      "\t *vere (REINT, &peride af (s)\t_sture)\n",
      "\n",
      "\tfout)\n",
      "3fo coc,\n",
      "\trerure_reuccock(corc_r_tare_kWum, usideud ifor+, cho_d!* R);\n",
      "\tre er_sk_cead_*tunc_d: UERGCLA_!T(D_pUR:ASEIFL;\n",
      "\troteroctsc \n",
      "----\n",
      "iter 7800, loss: 127.850633\n",
      "----\n",
      " syc = s rer_bhact_al?_foti+ hidd_mEaul= TcIL_+OUN Csq = (farber_cret, reyestrqu_rotteru(sbsprur = w tuct 0coc\t = e|toy forge = urnt supsy rnone_)) j gvaat->boxs-rnbe_onogacuad_yigide; *[\\ve\" */\n",
      "\trtare \n",
      "----\n",
      "iter 7900, loss: 128.164776\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Minimal character-level Vanilla RNN model. Written by Andrej Karpathy (@karpathy)\n",
    "BSD License\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "# data I/O\n",
    "data = open('linux_input.txt', 'r').read() # should be simple plain text file\n",
    "chars = list(set(data))\n",
    "data_size, vocab_size = len(data), len(chars)\n",
    "print('data has %d characters, %d unique.' % (data_size, vocab_size))\n",
    "char_to_ix = { ch:i for i,ch in enumerate(chars) }\n",
    "ix_to_char = { i:ch for i,ch in enumerate(chars) }\n",
    "\n",
    "# hyperparameters\n",
    "hidden_size = 100 # size of hidden layer of neurons\n",
    "seq_length = 50 # number of steps to unroll the RNN for\n",
    "learning_rate = 1e-2\n",
    "\n",
    "# model parameters\n",
    "#Wxh = np.random.randn(hidden_size, vocab_size)*0.01 # input to hidden\n",
    "#Whh = np.random.randn(hidden_size, hidden_size)*0.01 # hidden to hidden\n",
    "Why = np.random.randn(vocab_size, hidden_size)*0.01 # hidden to output\n",
    "Wxz = np.random.randn(hidden_size, vocab_size)*0.01 # input a actualizacion\n",
    "Whz = np.random.randn(hidden_size, hidden_size)*0.01 # hidden a actualizacion\n",
    "Wxn = np.random.randn(hidden_size, vocab_size)*0.01 \n",
    "Whn = np.random.randn(hidden_size, hidden_size)*0.01\n",
    "Wxr = np.random.randn(hidden_size, vocab_size)*0.01\n",
    "Whr = np.random.randn(hidden_size, hidden_size)*0.01\n",
    "br = np.zeros((hidden_size, 1))\n",
    "bn = np.zeros((hidden_size, 1))\n",
    "bz = np.zeros((hidden_size, 1)) # bias actualizacion\n",
    "#bh = np.zeros((hidden_size, 1)) # hidden bias\n",
    "by = np.zeros((vocab_size, 1)) # output bias\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def lossFun(inputs, targets, hprev):\n",
    "  \"\"\"\n",
    "  inputs,targets are both list of integers.\n",
    "  hprev is Hx1 array of initial hidden state\n",
    "  returns the loss, gradients on model parameters, and last hidden state\n",
    "  \"\"\"\n",
    "  xs, hs, zs, rs, ys, ps, hcs = {}, {}, {}, {}, {}, {}, {}\n",
    "  hs[-1] = np.copy(hprev)\n",
    "  loss = 0\n",
    "  # forward pass\n",
    "  for t in range(len(inputs)):\n",
    "\n",
    "    xs[t] = np.zeros((vocab_size,1)) # encode in 1-of-k representation\n",
    "    xs[t][inputs[t]] = 1\n",
    "    zs[t] = sigmoid(np.dot(Wxz, xs[t]) + np.dot(Whz, hs[t - 1]) + bz)\n",
    "    rs[t] = sigmoid(np.dot(Wxr, xs[t]) + np.dot(Whr, hs[t - 1] + br))\n",
    "    hcs[t] = np.tanh(np.dot(Wxn, xs[t]) + rs[t] * np.dot(Whn, hs[t - 1]) + bn) # hidden candidate state\n",
    "    hs[t] = (1 - zs[t]) * hs[t - 1] + zs[t] * hcs[t] # hidden state\n",
    "    ys[t] = np.dot(Why, hs[t]) + by # unnormalized log probabilities for next chars\n",
    "    ps[t] = np.exp(ys[t]) / np.sum(np.exp(ys[t])) # probabilities for next chars\n",
    "\n",
    "    loss += -np.log(ps[t][targets[t],0]) # softmax (cross-entropy loss)\n",
    "  # backward pass: compute gradients going backwards\n",
    "  dWxz, dWhz, dbz = np.zeros_like(Wxz), np.zeros_like(Whz), np.zeros_like(bz)\n",
    "  # (r) Reset gate\n",
    "  dWxr, dWhr, dbr = np.zeros_like(Wxr), np.zeros_like(Whr), np.zeros_like(br)\n",
    "  # (n) Candidate state\n",
    "  dWxn, dWhn, dbn = np.zeros_like(Wxn), np.zeros_like(Whn), np.zeros_like(bn)\n",
    "  dWhy, dby = np.zeros_like(Why), np.zeros_like(by)\n",
    "\n",
    "  dhnext = np.zeros_like(hs[0])\n",
    "  for t in reversed(range(len(inputs))):\n",
    "    dy = np.copy(ps[t])\n",
    "    dy[targets[t]] -= 1 # backprop into y. see http://cs231n.github.io/neural-networks-case-study/#grad if confused here\n",
    "    dWhy += np.dot(dy, hs[t].T)\n",
    "    dby += dy\n",
    "    dh = np.dot(Why.T, dy) + dhnext # backprop into h\n",
    "    dhc = dh * zs[t]\n",
    "    dz = dh * (hcs[t] - hs[t - 1])\n",
    "    dh_prev_h = dh * (1 - zs[t])\n",
    "    #dhraw = (1 - hs[t] * hs[t]) * dh # backprop through tanh nonlinearity\n",
    "    dzraw = (zs[t] * (1 - zs[t])) * dz\n",
    "    dhcraw = (1 - hcs[t]**2) * dhc\n",
    "\n",
    "    #dbh += dhraw\n",
    "    dbn += dhcraw\n",
    "    dWxn += np.dot(dhcraw, xs[t].T)\n",
    "\n",
    "    dr = dhcraw * np.dot(Whn, hs[t - 1])\n",
    "    dh_prev_hcs = np.dot(Whn.T, dhcraw * rs[t])\n",
    "    dWhn += np.dot(dhcraw * rs[t], hs[t - 1].T)\n",
    "\n",
    "    dbz += dzraw\n",
    "    dWxz += np.dot(dzraw, xs[t].T)\n",
    "\n",
    "    dh_prev_z = np.dot(Whz.T, dzraw)\n",
    "    dWhz += np.dot(dzraw, hs[t - 1].T)\n",
    "\n",
    "    drraw = (rs[t] * (1 - rs[t])) * dr\n",
    "    dbr += drraw\n",
    "    dWxr += np.dot(drraw, xs[t].T)\n",
    "\n",
    "    dh_prev_r = np.dot(Whr.T, drraw) \n",
    "    dWhr += np.dot(drraw, hs[t - 1].T)\n",
    "\n",
    "    dhnext = dh_prev_h + dh_prev_hcs + dh_prev_z + dh_prev_r\n",
    "  for dparam in [dWxz, dWhz, dbz, dWxr, dWhr, dbr, dWxn, dWhn, dbn, dWhy, dby]:\n",
    "    np.clip(dparam, -5, 5, out=dparam) # clip to mitigate exploding gradients\n",
    "  return loss, dWxz, dWhz, dbz, dWxr, dWhr, dbr, dWxn, dWhn, dbn, dWhy, dby, hs[len(inputs)-1]\n",
    "\n",
    "def sample(h, seed_ix, n):\n",
    "  \"\"\" \n",
    "  sample a sequence of integers from the model \n",
    "  h is memory state, seed_ix is seed letter for first time step\n",
    "  \"\"\"\n",
    "  x = np.zeros((vocab_size, 1))\n",
    "  x[seed_ix] = 1\n",
    "  ixes = []\n",
    "  for t in range(n):\n",
    "    r = sigmoid(np.dot(Wxr, x) + np.dot(Whr, h) + br) # Cuánto del estado anterior se olvida\n",
    "    z = sigmoid(np.dot(Wxz, x) + np.dot(Whz, h) + bz) # Cuánto del estado anterior se mantiene\n",
    "    h_can = np.tanh(np.dot(Wxn, x) + r * np.dot(Whn, h) + bn)\n",
    "    h = (1 - z) * h + z * h_can\n",
    "    y = np.dot(Why, h) + by\n",
    "    p = np.exp(y) / np.sum(np.exp(y))\n",
    "    ix = np.random.choice(range(vocab_size), p=p.ravel())\n",
    "    x = np.zeros((vocab_size, 1))\n",
    "    x[ix] = 1\n",
    "    ixes.append(ix)\n",
    "  return ixes\n",
    "\n",
    "n, p = 0, 0\n",
    "mWxz, mWhz, mbz = np.zeros_like(Wxz), np.zeros_like(Whz), np.zeros_like(bz)\n",
    "# (r) Reset gate\n",
    "mWxr, mWhr, mbr = np.zeros_like(Wxr), np.zeros_like(Whr), np.zeros_like(br)\n",
    "# (n) Candidate state\n",
    "mWxn, mWhn, mbn = np.zeros_like(Wxn), np.zeros_like(Whn), np.zeros_like(bn)\n",
    "\n",
    "# (Output)\n",
    "mWhy, mby = np.zeros_like(Why), np.zeros_like(by)\n",
    "smooth_loss = -np.log(1.0/vocab_size)*seq_length # loss at iteration 0\n",
    "while (n < 8000):\n",
    "  # prepare inputs (we're sweeping from left to right in steps seq_length long)\n",
    "  if p+seq_length+1 >= len(data) or n == 0: \n",
    "    hprev = np.zeros((hidden_size,1)) # reset RNN memory\n",
    "    p = 0 # go from start of data\n",
    "  inputs = [char_to_ix[ch] for ch in data[p:p+seq_length]]\n",
    "  targets = [char_to_ix[ch] for ch in data[p+1:p+seq_length+1]]\n",
    "\n",
    "  # sample from the model now and then\n",
    "  if n % 100 == 0:\n",
    "    sample_ix = sample(hprev, inputs[0], 200)\n",
    "    txt = ''.join(ix_to_char[ix] for ix in sample_ix)\n",
    "    print('----\\n %s \\n----' % (txt, ))\n",
    "\n",
    "  # forward seq_length characters through the net and fetch gradient\n",
    "  loss, dWxz, dWhz, dbz, dWxr, dWhr, dbr, dWxn, dWhn, dbn, dWhy, dby, hprev = lossFun(inputs, targets, hprev)  \n",
    "  smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
    "  if n % 100 == 0: print('iter %d, loss: %f' % (n, smooth_loss)) # print progress\n",
    "  \n",
    "  # perform parameter update with Adagrad\n",
    "  for param, dparam, mem in zip([Wxz, Whz, bz,\n",
    "                Wxr, Whr, br,\n",
    "                Wxn, Whn, bn,\n",
    "                Why, by], \n",
    "                                [dWxz, dWhz, dbz,\n",
    "                 dWxr, dWhr, dbr,\n",
    "                 dWxn, dWhn, dbn,\n",
    "                 dWhy, dby], \n",
    "                                [mWxz, mWhz, mbz,\n",
    "              mWxr, mWhr, mbr,\n",
    "              mWxn, mWhn, mbn,\n",
    "              mWhy, mby]):\n",
    "    mem += dparam * dparam\n",
    "    param += -learning_rate * dparam / np.sqrt(mem + 1e-8) # adagrad update\n",
    "\n",
    "  p += seq_length # move data pointer\n",
    "  n += 1 # iteration counter \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d9950c-e831-42d0-9484-a91519d31eeb",
   "metadata": {},
   "source": [
    "<p>En este caso, con seq_length = 50, la implementación de GRU no se estanca en cuanto a la reducción de su pérdida como la RNN común. Esto tiene sentido, ya que la RNN falla en las predicciones a largo plazo, mientras que la GRU puede seguir aprendiendo. También </p>\n",
    "\n",
    "<p>Ahora, si bajamos el seq_length a 25, la RNN debería comportarse mejor.</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
